{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "031c1afd9bee4632b3f37bcfaa65bb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99486bd6e8a8447abe00f0108abfe9fb",
              "IPY_MODEL_ae221d43774b4352994b8a5f9aa868c3",
              "IPY_MODEL_59a4a71421c7461a9643d7a91f812ba6"
            ],
            "layout": "IPY_MODEL_113a382c92034769badfa1091bed694d"
          }
        },
        "99486bd6e8a8447abe00f0108abfe9fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_160dd7a046f844768cfe834eead30aca",
            "placeholder": "​",
            "style": "IPY_MODEL_7fe1053e59804fe4987f23c586a8d7fe",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ae221d43774b4352994b8a5f9aa868c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79f6fe7e26b94b2494dd6c0daf91331a",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cfb6ac4c49e440b9981d88417ed2923",
            "value": 49
          }
        },
        "59a4a71421c7461a9643d7a91f812ba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9a3bb183e2c4403ac212df81cb6c3e3",
            "placeholder": "​",
            "style": "IPY_MODEL_813ee65ab3754245a2b256e8f29ce6e0",
            "value": " 49.0/49.0 [00:00&lt;00:00, 5.37kB/s]"
          }
        },
        "113a382c92034769badfa1091bed694d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "160dd7a046f844768cfe834eead30aca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fe1053e59804fe4987f23c586a8d7fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79f6fe7e26b94b2494dd6c0daf91331a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cfb6ac4c49e440b9981d88417ed2923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9a3bb183e2c4403ac212df81cb6c3e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "813ee65ab3754245a2b256e8f29ce6e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5286040503ba47bf964c74cbeed93e4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_867dc3234e634fe3a617f323079fb61b",
              "IPY_MODEL_44e6152d1be04143b378c61ce095d38d",
              "IPY_MODEL_5ce41b417bac4b558152a13e08137997"
            ],
            "layout": "IPY_MODEL_fb41602bef804ec6938e804c7b7b49fd"
          }
        },
        "867dc3234e634fe3a617f323079fb61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f3fa2202fe64b89a0e4f5d5c3774878",
            "placeholder": "​",
            "style": "IPY_MODEL_44f8f914cdfa4d9e9b97022819ea31eb",
            "value": "vocab.txt: 100%"
          }
        },
        "44e6152d1be04143b378c61ce095d38d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25b4dad543044bf2bd0b0c49884d426b",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b32161fc9e034a90b87731e148658b20",
            "value": 995526
          }
        },
        "5ce41b417bac4b558152a13e08137997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f898cc7c52644ca38ad997b76fa2c898",
            "placeholder": "​",
            "style": "IPY_MODEL_d5940ca163154f2095d9fae205904ffb",
            "value": " 996k/996k [00:00&lt;00:00, 5.27MB/s]"
          }
        },
        "fb41602bef804ec6938e804c7b7b49fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f3fa2202fe64b89a0e4f5d5c3774878": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44f8f914cdfa4d9e9b97022819ea31eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25b4dad543044bf2bd0b0c49884d426b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b32161fc9e034a90b87731e148658b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f898cc7c52644ca38ad997b76fa2c898": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5940ca163154f2095d9fae205904ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94b8b13fed1a459b869c2b380bf303cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cfed01c9aebc43c69d14e41267c029d4",
              "IPY_MODEL_f7f0e2037c4f408191574f831210abf1",
              "IPY_MODEL_7f4c9e8822194de3a0461fc873ab8308"
            ],
            "layout": "IPY_MODEL_55e90f3915d343e59f4fd4632b5de8ed"
          }
        },
        "cfed01c9aebc43c69d14e41267c029d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2841de79a24450d9435d63c0b19a5d4",
            "placeholder": "​",
            "style": "IPY_MODEL_d11e7a5189594a9297e66b4234ecefdf",
            "value": "tokenizer.json: 100%"
          }
        },
        "f7f0e2037c4f408191574f831210abf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e816317b8f1410b91e444039371a81b",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01647bbedf284d37add2e6241e37d33b",
            "value": 1961828
          }
        },
        "7f4c9e8822194de3a0461fc873ab8308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bed133dd566d477e89cf9116b2993388",
            "placeholder": "​",
            "style": "IPY_MODEL_be140d2670dd4d32bbafaf7c7e810da1",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 10.5MB/s]"
          }
        },
        "55e90f3915d343e59f4fd4632b5de8ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2841de79a24450d9435d63c0b19a5d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d11e7a5189594a9297e66b4234ecefdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e816317b8f1410b91e444039371a81b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01647bbedf284d37add2e6241e37d33b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bed133dd566d477e89cf9116b2993388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be140d2670dd4d32bbafaf7c7e810da1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a8c56ef6596474a8713aac1f5a2c60e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78b8983b88c5433d94dffc0657e38313",
              "IPY_MODEL_16a85cf0080a45eaa66b1b387ae8dc36",
              "IPY_MODEL_03c2974c96fc4bb698089a0787f9c176"
            ],
            "layout": "IPY_MODEL_20e26482a626460c8f5b89a94b48eb67"
          }
        },
        "78b8983b88c5433d94dffc0657e38313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e21ee1d6d1fb4e95adb27205158595f8",
            "placeholder": "​",
            "style": "IPY_MODEL_011a7ceb6b324b278cde2f2f3eb18d80",
            "value": "config.json: 100%"
          }
        },
        "16a85cf0080a45eaa66b1b387ae8dc36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83fcc19060f144bdbff6a0cd103ab627",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46398291f9354fec84c4970c7a45c927",
            "value": 625
          }
        },
        "03c2974c96fc4bb698089a0787f9c176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5aa3975b4f64520b0a799fa1a22e1ad",
            "placeholder": "​",
            "style": "IPY_MODEL_3e0296100c4049f4838bde22029b1764",
            "value": " 625/625 [00:00&lt;00:00, 52.1kB/s]"
          }
        },
        "20e26482a626460c8f5b89a94b48eb67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e21ee1d6d1fb4e95adb27205158595f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "011a7ceb6b324b278cde2f2f3eb18d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83fcc19060f144bdbff6a0cd103ab627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46398291f9354fec84c4970c7a45c927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5aa3975b4f64520b0a799fa1a22e1ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e0296100c4049f4838bde22029b1764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "991758ec925e4fc1a211788e0a4ae608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_526e45c638c745f09d86b5b0f4e55003",
              "IPY_MODEL_082de4456a894dbbb70668f840c13018",
              "IPY_MODEL_43213750545341a78310fd8e88507bba"
            ],
            "layout": "IPY_MODEL_5c4583024b5648f19628c742b6fa1124"
          }
        },
        "526e45c638c745f09d86b5b0f4e55003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6d6a704f9af4952944a487566dee509",
            "placeholder": "​",
            "style": "IPY_MODEL_b726a8ba442743af8d980ba4e0131f1c",
            "value": "model.safetensors: 100%"
          }
        },
        "082de4456a894dbbb70668f840c13018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d882b7e120b48b6a4c2cc233e12270f",
            "max": 714290682,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee705db8bee64c5c8127f65d67624c17",
            "value": 714290682
          }
        },
        "43213750545341a78310fd8e88507bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_197883425ba24422b59426b7d19e623c",
            "placeholder": "​",
            "style": "IPY_MODEL_2ec40eecfb2b4da297d5b21548edf37e",
            "value": " 714M/714M [00:11&lt;00:00, 35.8MB/s]"
          }
        },
        "5c4583024b5648f19628c742b6fa1124": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6d6a704f9af4952944a487566dee509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b726a8ba442743af8d980ba4e0131f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d882b7e120b48b6a4c2cc233e12270f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee705db8bee64c5c8127f65d67624c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "197883425ba24422b59426b7d19e623c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ec40eecfb2b4da297d5b21548edf37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarioSigal/Aprendizaje-Automatico-I-y-II/blob/main/TP2/TP_2_AA_RNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TP2 Aprendizaje Automatico\n",
        "Archivo de los modelos basados en RNN"
      ],
      "metadata": {
        "id": "LHJFvvd8rclU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IMPORTS & DRIVE\n"
      ],
      "metadata": {
        "id": "GJ8imGsu_vew"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjfXeaWE_og8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from typing import List, Dict, Any\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargar drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgdLKjU1JUOk",
        "outputId": "aa91b5a2-47ad-49df-93c0-514271badecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TOKENIZER & BERT EMBEDDINGS"
      ],
      "metadata": {
        "id": "uVHH_Ow__8fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cargamos bert\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "model_bert = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "model_bert.eval()"
      ],
      "metadata": {
        "id": "LYMyfzMG_3JA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 993,
          "referenced_widgets": [
            "031c1afd9bee4632b3f37bcfaa65bb6f",
            "99486bd6e8a8447abe00f0108abfe9fb",
            "ae221d43774b4352994b8a5f9aa868c3",
            "59a4a71421c7461a9643d7a91f812ba6",
            "113a382c92034769badfa1091bed694d",
            "160dd7a046f844768cfe834eead30aca",
            "7fe1053e59804fe4987f23c586a8d7fe",
            "79f6fe7e26b94b2494dd6c0daf91331a",
            "0cfb6ac4c49e440b9981d88417ed2923",
            "c9a3bb183e2c4403ac212df81cb6c3e3",
            "813ee65ab3754245a2b256e8f29ce6e0",
            "5286040503ba47bf964c74cbeed93e4f",
            "867dc3234e634fe3a617f323079fb61b",
            "44e6152d1be04143b378c61ce095d38d",
            "5ce41b417bac4b558152a13e08137997",
            "fb41602bef804ec6938e804c7b7b49fd",
            "5f3fa2202fe64b89a0e4f5d5c3774878",
            "44f8f914cdfa4d9e9b97022819ea31eb",
            "25b4dad543044bf2bd0b0c49884d426b",
            "b32161fc9e034a90b87731e148658b20",
            "f898cc7c52644ca38ad997b76fa2c898",
            "d5940ca163154f2095d9fae205904ffb",
            "94b8b13fed1a459b869c2b380bf303cd",
            "cfed01c9aebc43c69d14e41267c029d4",
            "f7f0e2037c4f408191574f831210abf1",
            "7f4c9e8822194de3a0461fc873ab8308",
            "55e90f3915d343e59f4fd4632b5de8ed",
            "a2841de79a24450d9435d63c0b19a5d4",
            "d11e7a5189594a9297e66b4234ecefdf",
            "7e816317b8f1410b91e444039371a81b",
            "01647bbedf284d37add2e6241e37d33b",
            "bed133dd566d477e89cf9116b2993388",
            "be140d2670dd4d32bbafaf7c7e810da1",
            "2a8c56ef6596474a8713aac1f5a2c60e",
            "78b8983b88c5433d94dffc0657e38313",
            "16a85cf0080a45eaa66b1b387ae8dc36",
            "03c2974c96fc4bb698089a0787f9c176",
            "20e26482a626460c8f5b89a94b48eb67",
            "e21ee1d6d1fb4e95adb27205158595f8",
            "011a7ceb6b324b278cde2f2f3eb18d80",
            "83fcc19060f144bdbff6a0cd103ab627",
            "46398291f9354fec84c4970c7a45c927",
            "f5aa3975b4f64520b0a799fa1a22e1ad",
            "3e0296100c4049f4838bde22029b1764",
            "991758ec925e4fc1a211788e0a4ae608",
            "526e45c638c745f09d86b5b0f4e55003",
            "082de4456a894dbbb70668f840c13018",
            "43213750545341a78310fd8e88507bba",
            "5c4583024b5648f19628c742b6fa1124",
            "f6d6a704f9af4952944a487566dee509",
            "b726a8ba442743af8d980ba4e0131f1c",
            "3d882b7e120b48b6a4c2cc233e12270f",
            "ee705db8bee64c5c8127f65d67624c17",
            "197883425ba24422b59426b7d19e623c",
            "2ec40eecfb2b4da297d5b21548edf37e"
          ]
        },
        "outputId": "c341b904-54ca-4f17-be0e-9f908cbd110e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "031c1afd9bee4632b3f37bcfaa65bb6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5286040503ba47bf964c74cbeed93e4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94b8b13fed1a459b869c2b380bf303cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a8c56ef6596474a8713aac1f5a2c60e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "991758ec925e4fc1a211788e0a4ae608"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DATASET"
      ],
      "metadata": {
        "id": "6qteVmN1qvss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ABRIMOS Y DAMOS FORMATO AL DATASET"
      ],
      "metadata": {
        "id": "bsVa0ABkrJ34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/colab/dataset_datos_total3.csv\")"
      ],
      "metadata": {
        "id": "T8Hgq2B7uiQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupar tokens por párrafo\n",
        "df_por_parrafos = df.groupby(\"instancia_id\").agg({\n",
        "    \"token_id\":list,\n",
        "    \"token\": list,\n",
        "    \"punt_inicial\": list,\n",
        "    \"punt_final\": list,\n",
        "    \"capitalización\": list\n",
        "}).reset_index()\n"
      ],
      "metadata": {
        "id": "I3yuvW8Esk5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CREAMOS CLASE DATASET DE PYTORCH"
      ],
      "metadata": {
        "id": "A1Zpp0aEjuXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class DynamicEmbeddingDataset(Dataset):\n",
        "    \"\"\"Dataset de pytorch que calcula embeddings dinámicamente\"\"\"\n",
        "    def __init__(self, df, tokenizer, bert_model, modo=\"train\"):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.bert_model = bert_model\n",
        "        self.embedding_matrix = bert_model.embeddings.word_embeddings.weight\n",
        "        self.embedding_matrix.requires_grad = False\n",
        "        self.modo = modo  # \"train\" o \"pred\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        token_id_list = row[\"token_id\"]\n",
        "\n",
        "        # Calcular embeddings dinámicamente\n",
        "        token_embeddings = []\n",
        "        for token_id in token_id_list:\n",
        "            if token_id is None or token_id == self.tokenizer.unk_token_id:\n",
        "                token_id = self.tokenizer.unk_token_id\n",
        "            emb = self.embedding_matrix[token_id].detach()\n",
        "            token_embeddings.append(emb)\n",
        "\n",
        "        # Convertir a tensor\n",
        "        if token_embeddings:\n",
        "            embeddings = torch.stack(token_embeddings)\n",
        "        else:\n",
        "            embeddings = torch.empty(0, self.embedding_matrix.shape[1])\n",
        "\n",
        "        if self.modo == \"pred\": #para predecir, no devuelve los labels\n",
        "            return embeddings, None\n",
        "\n",
        "        # Preparar labels\n",
        "        labels = {\n",
        "            \"punt_inicial\": torch.tensor(row[\"punt_inicial\"], dtype=torch.long),\n",
        "            \"punt_final\": torch.tensor(row[\"punt_final\"], dtype=torch.long),\n",
        "            \"capitalización\": torch.tensor(row[\"capitalización\"], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "        return embeddings, labels"
      ],
      "metadata": {
        "id": "OBX8JOtxkzcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###FUNCIÓN DE PADDING"
      ],
      "metadata": {
        "id": "x65RnXFBwyB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    batch: lista de tuplas (embeddings, labels)\n",
        "    \"\"\"\n",
        "    embeddings_list, labels_list = zip(*batch)\n",
        "\n",
        "    # Pad embeddings (seq_len, embedding_dim) -> (batch_size, max_seq_len, embedding_dim)\n",
        "    embeddings_padded = pad_sequence(embeddings_list, batch_first=True, padding_value=0.0)\n",
        "\n",
        "    if labels_list[0] is None: # si estamos prediciendo, no tenemos labels\n",
        "        return embeddings_padded, None\n",
        "\n",
        "    # Pad labels\n",
        "    punt_inicial = pad_sequence([l[\"punt_inicial\"] for l in labels_list], batch_first=True, padding_value=-100).long()\n",
        "    punt_final = pad_sequence([l[\"punt_final\"] for l in labels_list], batch_first=True, padding_value=-100).long()\n",
        "    capitalizacion = pad_sequence([l[\"capitalización\"] for l in labels_list], batch_first=True, padding_value=-100).long()\n",
        "\n",
        "    return embeddings_padded, {\n",
        "        \"punt_inicial\": punt_inicial,\n",
        "        \"punt_final\": punt_final,\n",
        "        \"capitalizacion\": capitalizacion\n",
        "    }"
      ],
      "metadata": {
        "id": "a66xammXw1L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ARQUITECTURAS"
      ],
      "metadata": {
        "id": "W89WmANfqlJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###RNN Unidireccional"
      ],
      "metadata": {
        "id": "uhpy5I7nAGf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_Unidireccional(nn.Module):\n",
        "    def __init__(self, embedding_dim = 768, hidden_dim1 = 128, hidden_dim2 = 32, num_layers= 2, dropout= 0.4):\n",
        "        super(RNN_Unidireccional, self).__init__()\n",
        "\n",
        "        # LSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_dim1,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout,\n",
        "            bidirectional=False  # Unidireccional\n",
        "            )\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Salidas\n",
        "        self.punt_inicial_ff = nn.Sequential(\n",
        "            nn.Linear(hidden_dim1, hidden_dim2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim2, 2)\n",
        "            )\n",
        "        self.punt_final_ff = nn.Sequential(\n",
        "            nn.Linear(hidden_dim1, hidden_dim2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim2, 4)\n",
        "            )\n",
        "        self.capital_ff = nn.Sequential(\n",
        "            nn.Linear(hidden_dim1, hidden_dim2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim2, 4)\n",
        "            )\n",
        "\n",
        "    def forward(self, embeddings):\n",
        "        \"\"\"\n",
        "        embeddings: tensor de forma (batch_size, seq_len, embedding_dim)\n",
        "        \"\"\"\n",
        "        # Pasamos los embeddings por la lstm\n",
        "        outputs, _ = self.lstm(embeddings)\n",
        "\n",
        "        # Les hacemos dropout a los outputs\n",
        "        outputs = self.dropout(outputs)\n",
        "\n",
        "        # Pasamos los outputs de la lstm por las salidas\n",
        "        punt_inicial_logits = self.punt_inicial_ff(outputs)\n",
        "        punt_final_logits = self.punt_final_ff(outputs)\n",
        "        capital_logits = self.capital_ff(outputs)\n",
        "\n",
        "        return {\n",
        "            \"puntuación inicial\": punt_inicial_logits,\n",
        "            \"puntuación final\": punt_final_logits,\n",
        "            \"capitalización\": capital_logits,\n",
        "        }\n"
      ],
      "metadata": {
        "id": "rKk-_53cAtTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN Bidireccional\n"
      ],
      "metadata": {
        "id": "swyed0hyHn2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_Bidireccional(nn.Module):\n",
        "    def __init__(self, embedding_dim = 768, hidden_dim1 = 64, hidden_dim2 = 32, num_layers= 2, dropout= 0.4): #reducimos hidden_dim1 para equiparar con la red unidireccional( 64*2 = 128)\n",
        "        super(RNN_Bidireccional, self).__init__()\n",
        "\n",
        "        # LSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_dim1,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout,\n",
        "            bidirectional=True  # Bidireccional\n",
        "            )\n",
        "\n",
        "        lstm_output_dim = hidden_dim1 * 2 #128 igual que en la Unidireccinal\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Salidas\n",
        "        self.punt_inicial_ff = nn.Sequential(\n",
        "            nn.Linear(lstm_output_dim, hidden_dim2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim2, 2)\n",
        "            )\n",
        "        self.punt_final_ff = nn.Sequential(\n",
        "            nn.Linear(lstm_output_dim, hidden_dim2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim2, 4)\n",
        "            )\n",
        "        self.capital_ff = nn.Sequential(\n",
        "            nn.Linear(lstm_output_dim, hidden_dim2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim2, 4)\n",
        "            )\n",
        "\n",
        "    def forward(self, embeddings):\n",
        "        \"\"\"\n",
        "        embeddings: tensor de forma (batch_size, seq_len, embedding_dim)\n",
        "        \"\"\"\n",
        "        # Pasamos los embeddings por la lstm\n",
        "        outputs, _ = self.lstm(embeddings)\n",
        "\n",
        "        # Les hacemos dropout a los outputs\n",
        "        outputs = self.dropout(outputs)\n",
        "\n",
        "        # Pasamos los outputs de la lstm por las salidas\n",
        "        punt_inicial_logits = self.punt_inicial_ff(outputs)\n",
        "        punt_final_logits = self.punt_final_ff(outputs)\n",
        "        capital_logits = self.capital_ff(outputs)\n",
        "\n",
        "        return {\n",
        "            \"puntuación inicial\": punt_inicial_logits,\n",
        "            \"puntuación final\": punt_final_logits,\n",
        "            \"capitalización\": capital_logits,\n",
        "        }"
      ],
      "metadata": {
        "id": "shJOmhfqmuuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ENTRENAMIENTO DE LOS MODELOS"
      ],
      "metadata": {
        "id": "gg_COwTOxHSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.utils as nn_utils\n",
        "\n",
        "# Dividir en train/validation/test\n",
        "train_df, temp = train_test_split(df_por_parrafos, test_size=0.2, shuffle=True, random_state=42)\n",
        "\n",
        "val_df, test_df = train_test_split(temp, test_size=0.5, shuffle=True, random_state=42)\n",
        "\n",
        "train_dataset = DynamicEmbeddingDataset(train_df.reset_index(drop=True), tokenizer, model_bert)\n",
        "val_dataset = DynamicEmbeddingDataset(val_df.reset_index(drop=True), tokenizer, model_bert)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "3zALNZA7iF2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ENTRENAMIENTO UNIDIRECCIONAL\n",
        "entrenamos por 30 epochs quedandonos con todos los modelos y viendo cual es el mejor segun como varia la loss, en train y val, epoch por epoch.\n",
        "\n",
        "MEJOR MODELO: ÉPOCA 12"
      ],
      "metadata": {
        "id": "FjrecG48ebez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import torch.nn.utils as nn_utils\n",
        "\n",
        "model = RNN_Unidireccional(embedding_dim=768, hidden_dim1=128, hidden_dim2=32,  num_layers=2, dropout=0.4)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "# Mover BERT a la misma device\n",
        "model_bert = model_bert.to(device)\n",
        "\n",
        "# Optimizador con weight decay (regularización L2)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.2, patience=3\n",
        ")\n",
        "\n",
        "# Pesos diferentes para cada tarea (opcional, ajustar según importancia)\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=-100, label_smoothing=0.1)\n",
        "\n",
        "# Gradient clipping\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "num_epochs = 30\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "early_stop_patience = 30\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # ENTRENAMIENTO\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    total_loss_inicial = 0\n",
        "    total_loss_final = 0\n",
        "    total_loss_cap = 0\n",
        "\n",
        "    for embeddings, labels in train_loader:\n",
        "        embeddings = embeddings.to(device)\n",
        "        labels = {k: v.to(device) for k, v in labels.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(embeddings)\n",
        "\n",
        "        loss_inicial = 2*criterion(outputs[\"puntuación inicial\"].permute(0,2,1), labels[\"punt_inicial\"]) # le ponemos 2* a loss inicial para equiparar en magnitud con las demas\n",
        "        loss_final = criterion(outputs[\"puntuación final\"].permute(0,2,1), labels[\"punt_final\"])\n",
        "        loss_cap = criterion(outputs[\"capitalización\"].permute(0,2,1), labels[\"capitalizacion\"])\n",
        "\n",
        "        # Pérdida total\n",
        "        loss = loss_inicial + loss_final + loss_cap\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping para evitar gradientes explosivos\n",
        "        nn_utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        total_loss_inicial += loss_inicial.item()\n",
        "        total_loss_final += loss_final.item()\n",
        "        total_loss_cap += loss_cap.item()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    val_loss_inicial = 0\n",
        "    val_loss_final = 0\n",
        "    val_loss_cap = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for embeddings, labels in val_loader:\n",
        "            embeddings = embeddings.to(device)\n",
        "            labels = {k: v.to(device) for k, v in labels.items()}\n",
        "\n",
        "            outputs = model(embeddings)\n",
        "\n",
        "            loss_inicial = 2*criterion(outputs[\"puntuación inicial\"].permute(0,2,1), labels[\"punt_inicial\"])  # le ponemos 2* a loss inicial para equiparar en magnitud con las demas\n",
        "\n",
        "            loss_final = criterion(outputs[\"puntuación final\"].permute(0,2,1), labels[\"punt_final\"])\n",
        "\n",
        "            loss_cap = criterion(outputs[\"capitalización\"].permute(0,2,1), labels[\"capitalizacion\"])\n",
        "\n",
        "            loss = loss_inicial + loss_final + loss_cap\n",
        "\n",
        "            total_val_loss += loss.item()\n",
        "            val_loss_inicial += loss_inicial.item()\n",
        "            val_loss_final += loss_final.item()\n",
        "            val_loss_cap += loss_cap.item()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "    # Actualizar learning rate\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    # Imprimir métricas detalladas\n",
        "    print(f\"Época {epoch+1}/{num_epochs}\")\n",
        "    print(f\"  Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "    print(f\"  Train - Inicial: {total_loss_inicial/len(train_loader):.4f}, Final: {total_loss_final/len(train_loader):.4f}, Cap: {total_loss_cap/len(train_loader):.4f}\")\n",
        "    print(f\"  Val   - Inicial: {val_loss_inicial/len(val_loader):.4f}, Final: {val_loss_final/len(val_loader):.4f}, Cap: {val_loss_cap/len(val_loader):.4f}\")\n",
        "    print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "\n",
        "    # Guardar cada epoca\n",
        "    ruta_epoca = f\"/content/drive/MyDrive/colab/modelosU/modelo_epoca_{epoch+1}.pt\"\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'val_loss': avg_val_loss,\n",
        "        }, ruta_epoca)\n",
        "\n",
        "\n",
        "    # Guardar mejor modelo\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0\n",
        "        ruta_mejor_modelo = \"/content/drive/MyDrive/colab/modelosU/mejor_modelo.pt\"\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_loss': avg_val_loss,\n",
        "        }, ruta_mejor_modelo)\n",
        "        print(f\"  ✓ Mejor modelo actualizado (Val Loss: {avg_val_loss:.4f})\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"  Sin mejora ({patience_counter}/{early_stop_patience})\")\n",
        "\n",
        "    # Early stopping\n",
        "    if patience_counter >= early_stop_patience:\n",
        "        print(f\"\\nEarly stopping en época {epoch+1}\")\n",
        "        break\n",
        "\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "\n",
        "print(f\"\\nEntrenamiento completado!\")\n",
        "print(f\"Mejor modelo guardado en: {ruta_mejor_modelo}\")\n",
        "print(f\"Mejor Val Loss: {best_val_loss:.4f}\")\n",
        "\n",
        "#Mostramos lo que printeo durante el entrenamiento\n",
        "\n",
        "\"\"\"\n",
        "Época 1/30\n",
        "  Train Loss: 1.4731 | Val Loss: 1.4118\n",
        "  Train - Inicial: 0.4391, Final: 0.5594, Cap: 0.4747\n",
        "  Val   - Inicial: 0.4289, Final: 0.5407, Cap: 0.4423\n",
        "  LR: 0.001000\n",
        "  ✓ Mejor modelo actualizado (Val Loss: 1.4118)\n",
        "------------------------------------------------------------\n",
        "Época 2/30\n",
        "  Train Loss: 1.4212 | Val Loss: 1.3945\n",
        "  Train - Inicial: 0.4318, Final: 0.5423, Cap: 0.4470\n",
        "  Val   - Inicial: 0.4282, Final: 0.5333, Cap: 0.4330\n",
        "  LR: 0.001000\n",
        "  ✓ Mejor modelo actualizado (Val Loss: 1.3945)\n",
        "------------------------------------------------------------\n",
        "Época 3/30\n",
        "  Train Loss: 1.4088 | Val Loss: 1.3856\n",
        "  Train - Inicial: 0.4308, Final: 0.5378, Cap: 0.4401\n",
        "  Val   - Inicial: 0.4277, Final: 0.5289, Cap: 0.4290\n",
        "  LR: 0.001000\n",
        "  ✓ Mejor modelo actualizado (Val Loss: 1.3856)\n",
        "------------------------------------------------------------\n",
        "Época 4/30\n",
        "  Train Loss: 1.4012 | Val Loss: 1.3827\n",
        "  Train - Inicial: 0.4304, Final: 0.5351, Cap: 0.4358\n",
        "  Val   - Inicial: 0.4276, Final: 0.5277, Cap: 0.4275\n",
        "  LR: 0.001000\n",
        "  ✓ Mejor modelo actualizado (Val Loss: 1.3827)\n",
        "------------------------------------------------------------\n",
        "Época 5/30\n",
        "  Train Loss: 1.3952 | Val Loss: 1.3796\n",
        "  Train - Inicial: 0.4301, Final: 0.5329, Cap: 0.4322\n",
        "  Val   - Inicial: 0.4272, Final: 0.5269, Cap: 0.4255\n",
        "  LR: 0.001000\n",
        "  ✓ Mejor modelo actualizado (Val Loss: 1.3796)\n",
        "------------------------------------------------------------\n",
        "Época 6/30\n",
        "  Train Loss: 1.3904 | Val Loss: 1.3784\n",
        "  Train - Inicial: 0.4298, Final: 0.5315, Cap: 0.4291\n",
        "  Val   - Inicial: 0.4273, Final: 0.5244, Cap: 0.4266\n",
        "  LR: 0.001000\n",
        "  ✓ Mejor modelo actualizado (Val Loss: 1.3784)\n",
        "------------------------------------------------------------\n",
        "Época 7/30\n",
        "  Train Loss: 1.3865 | Val Loss: 1.3751\n",
        "  Train - Inicial: 0.4295, Final: 0.5302, Cap: 0.4268\n",
        "  Val   - Inicial: 0.4270, Final: 0.5240, Cap: 0.4241\n",
        "  LR: 0.001000\n",
        "  ✓ Mejor modelo actualizado (Val Loss: 1.3751)\n",
        "------------------------------------------------------------\n",
        "Época 8/30\n",
        "  Train Loss: 1.3829 | Val Loss: 1.3750\n",
        "  Train - Inicial: 0.4292, Final: 0.5292, Cap: 0.4245\n",
        "  Val   - Inicial: 0.4270, Final: 0.5233, Cap: 0.4247\n",
        "  LR: 0.001000\n",
        "  ✓ Mejor modelo actualizado (Val Loss: 1.3750)\n",
        "------------------------------------------------------------\n",
        "Época 9/30\n",
        "  Train Loss: 1.3799 | Val Loss: 1.3747\n",
        "  Train - Inicial: 0.4290, Final: 0.5283, Cap: 0.4226\n",
        "  Val   - Inicial: 0.4271, Final: 0.5231, Cap: 0.4246\n",
        "  LR: 0.001000\n",
        "  ✓ Mejor modelo actualizado (Val Loss: 1.3747)\n",
        "------------------------------------------------------------\n",
        "Época 10/30\n",
        "  Train Loss: 1.3770 | Val Loss: 1.3750\n",
        "  Train - Inicial: 0.4287, Final: 0.5274, Cap: 0.4208\n",
        "  Val   - Inicial: 0.4272, Final: 0.5231, Cap: 0.4247\n",
        "  LR: 0.001000\n",
        "  Sin mejora (1/30)\n",
        "------------------------------------------------------------\n",
        "Época 11/30\n",
        "  Train Loss: 1.3750 | Val Loss: 1.3759\n",
        "  Train - Inicial: 0.4286, Final: 0.5268, Cap: 0.4197\n",
        "  Val   - Inicial: 0.4272, Final: 0.5228, Cap: 0.4260\n",
        "  LR: 0.001000\n",
        "  Sin mejora (2/30)\n",
        "------------------------------------------------------------\n",
        "Época 12/30\n",
        "  Train Loss: 1.3729 | Val Loss: 1.3747\n",
        "  Train - Inicial: 0.4285, Final: 0.5262, Cap: 0.4182\n",
        "  Val   - Inicial: 0.4271, Final: 0.5221, Cap: 0.4254\n",
        "  LR: 0.001000\n",
        "  ✓ Mejor modelo actualizado (Val Loss: 1.3747)\n",
        "------------------------------------------------------------\n",
        "Época 13/30\n",
        "  Train Loss: 1.3708 | Val Loss: 1.3758\n",
        "  Train - Inicial: 0.4282, Final: 0.5257, Cap: 0.4169\n",
        "  Val   - Inicial: 0.4272, Final: 0.5222, Cap: 0.4265\n",
        "  LR: 0.000200\n",
        "  Sin mejora (1/30)\n",
        "------------------------------------------------------------\n",
        "Época 14/30\n",
        "  Train Loss: 1.3635 | Val Loss: 1.3755\n",
        "  Train - Inicial: 0.4275, Final: 0.5231, Cap: 0.4129\n",
        "  Val   - Inicial: 0.4270, Final: 0.5218, Cap: 0.4266\n",
        "  LR: 0.000200\n",
        "  Sin mejora (2/30)\n",
        "------------------------------------------------------------\n",
        "Época 15/30\n",
        "  Train Loss: 1.3618 | Val Loss: 1.3758\n",
        "  Train - Inicial: 0.4273, Final: 0.5227, Cap: 0.4118\n",
        "  Val   - Inicial: 0.4270, Final: 0.5216, Cap: 0.4272\n",
        "  LR: 0.000200\n",
        "  Sin mejora (3/30)\n",
        "------------------------------------------------------------\n",
        "Época 16/30\n",
        "  Train Loss: 1.3604 | Val Loss: 1.3763\n",
        "  Train - Inicial: 0.4272, Final: 0.5223, Cap: 0.4109\n",
        "  Val   - Inicial: 0.4270, Final: 0.5215, Cap: 0.4277\n",
        "  LR: 0.000200\n",
        "  Sin mejora (4/30)\n",
        "------------------------------------------------------------\n",
        "Época 17/30\n",
        "  Train Loss: 1.3595 | Val Loss: 1.3765\n",
        "  Train - Inicial: 0.4271, Final: 0.5221, Cap: 0.4103\n",
        "  Val   - Inicial: 0.4270, Final: 0.5217, Cap: 0.4278\n",
        "  LR: 0.000040\n",
        "  Sin mejora (5/30)\n",
        "------------------------------------------------------------\n",
        "Época 18/30\n",
        "  Train Loss: 1.3576 | Val Loss: 1.3773\n",
        "  Train - Inicial: 0.4269, Final: 0.5213, Cap: 0.4094\n",
        "  Val   - Inicial: 0.4271, Final: 0.5216, Cap: 0.4286\n",
        "  LR: 0.000040\n",
        "  Sin mejora (6/30)\n",
        "------------------------------------------------------------\n",
        "Época 19/30\n",
        "  Train Loss: 1.3571 | Val Loss: 1.3773\n",
        "  Train - Inicial: 0.4268, Final: 0.5212, Cap: 0.4092\n",
        "  Val   - Inicial: 0.4271, Final: 0.5216, Cap: 0.4286\n",
        "  LR: 0.000040\n",
        "  Sin mejora (7/30)\n",
        "------------------------------------------------------------\n",
        "Época 20/30\n",
        "  Train Loss: 1.3567 | Val Loss: 1.3776\n",
        "  Train - Inicial: 0.4267, Final: 0.5211, Cap: 0.4089\n",
        "  Val   - Inicial: 0.4271, Final: 0.5217, Cap: 0.4288\n",
        "  LR: 0.000040\n",
        "  Sin mejora (8/30)\n",
        "------------------------------------------------------------\n",
        "Época 21/30\n",
        "  Train Loss: 1.3570 | Val Loss: 1.3775\n",
        "  Train - Inicial: 0.4268, Final: 0.5212, Cap: 0.4089\n",
        "  Val   - Inicial: 0.4271, Final: 0.5217, Cap: 0.4287\n",
        "  LR: 0.000008\n",
        "  Sin mejora (9/30)\n",
        "------------------------------------------------------------\n",
        "Época 22/30\n",
        "  Train Loss: 1.3564 | Val Loss: 1.3776\n",
        "  Train - Inicial: 0.4268, Final: 0.5208, Cap: 0.4088\n",
        "  Val   - Inicial: 0.4271, Final: 0.5216, Cap: 0.4289\n",
        "  LR: 0.000008\n",
        "  Sin mejora (10/30)\n",
        "------------------------------------------------------------\n",
        "Época 23/30\n",
        "  Train Loss: 1.3562 | Val Loss: 1.3778\n",
        "  Train - Inicial: 0.4266, Final: 0.5209, Cap: 0.4086\n",
        "  Val   - Inicial: 0.4271, Final: 0.5216, Cap: 0.4291\n",
        "  LR: 0.000008\n",
        "  Sin mejora (11/30)\n",
        "------------------------------------------------------------\n",
        "Época 24/30\n",
        "  Train Loss: 1.3562 | Val Loss: 1.3777\n",
        "  Train - Inicial: 0.4266, Final: 0.5209, Cap: 0.4086\n",
        "  Val   - Inicial: 0.4271, Final: 0.5217, Cap: 0.4290\n",
        "  LR: 0.000008\n",
        "  Sin mejora (12/30)\n",
        "------------------------------------------------------------\n",
        "Época 25/30\n",
        "  Train Loss: 1.3560 | Val Loss: 1.3778\n",
        "  Train - Inicial: 0.4266, Final: 0.5207, Cap: 0.4086\n",
        "  Val   - Inicial: 0.4271, Final: 0.5216, Cap: 0.4290\n",
        "  LR: 0.000002\n",
        "  Sin mejora (13/30)\n",
        "------------------------------------------------------------\n",
        "Época 26/30\n",
        "  Train Loss: 1.3561 | Val Loss: 1.3778\n",
        "  Train - Inicial: 0.4266, Final: 0.5209, Cap: 0.4086\n",
        "  Val   - Inicial: 0.4271, Final: 0.5216, Cap: 0.4290\n",
        "  LR: 0.000002\n",
        "  Sin mejora (14/30)\n",
        "------------------------------------------------------------\n",
        "Época 27/30\n",
        "  Train Loss: 1.3561 | Val Loss: 1.3778\n",
        "  Train - Inicial: 0.4267, Final: 0.5209, Cap: 0.4085\n",
        "  Val   - Inicial: 0.4271, Final: 0.5216, Cap: 0.4290\n",
        "  LR: 0.000002\n",
        "  Sin mejora (15/30)\n",
        "------------------------------------------------------------\n",
        "Época 28/30\n",
        "  Train Loss: 1.3562 | Val Loss: 1.3778\n",
        "  Train - Inicial: 0.4267, Final: 0.5210, Cap: 0.4085\n",
        "  Val   - Inicial: 0.4271, Final: 0.5216, Cap: 0.4291\n",
        "  LR: 0.000002\n",
        "  Sin mejora (16/30)\n",
        "------------------------------------------------------------\n",
        "Época 29/30\n",
        "  Train Loss: 1.3560 | Val Loss: 1.3778\n",
        "  Train - Inicial: 0.4266, Final: 0.5209, Cap: 0.4085\n",
        "  Val   - Inicial: 0.4271, Final: 0.5216, Cap: 0.4291\n",
        "  LR: 0.000000\n",
        "  Sin mejora (17/30)\n",
        "------------------------------------------------------------\n",
        "Época 30/30\n",
        "  Train Loss: 1.3561 | Val Loss: 1.3778\n",
        "  Train - Inicial: 0.4266, Final: 0.5209, Cap: 0.4086\n",
        "  Val   - Inicial: 0.4271, Final: 0.5216, Cap: 0.4291\n",
        "  LR: 0.000000\n",
        "  Sin mejora (18/30)\n",
        "------------------------------------------------------------\n",
        "\n",
        "Entrenamiento completado!\n",
        "Mejor modelo guardado en: /content/drive/MyDrive/colab/modelosU/mejor_modelo.pt\n",
        "Mejor Val Loss: 1.3747\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "T6miBWEAxWsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ENTRENAMIENTO BIDIRECCIONAL\n",
        "entrenamos por 30 epochs quedandonos con todos los modelos y viendo cual es el mejor segun como varia la loss, en train y val, epoch por epoch.\n",
        "\n",
        "MEJOR MODELO: ÉPOCA 8"
      ],
      "metadata": {
        "id": "_mvv2Fz3ejX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN_Bidireccional(embedding_dim=768, hidden_dim1=64, hidden_dim2=32,  num_layers=2, dropout=0.4) # 64 para que 64*2 sea 128\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "# Mover BERT a la misma device\n",
        "model_bert = model_bert.to(device)\n",
        "\n",
        "# Optimizador con weight decay (regularización L2)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.2, patience=3\n",
        ")\n",
        "\n",
        "# Pesos diferentes para cada tarea (opcional, ajustar según importancia)\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=-100, label_smoothing=0.1)\n",
        "\n",
        "# Gradient clipping\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "num_epochs = 30\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "early_stop_patience = 30\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # ENTRENAMIENTO\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    total_loss_inicial = 0\n",
        "    total_loss_final = 0\n",
        "    total_loss_cap = 0\n",
        "\n",
        "    for embeddings, labels in train_loader:\n",
        "        embeddings = embeddings.to(device)\n",
        "        labels = {k: v.to(device) for k, v in labels.items()}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(embeddings)\n",
        "\n",
        "        loss_inicial = 2*criterion(outputs[\"puntuación inicial\"].permute(0,2,1), labels[\"punt_inicial\"]) # le ponemos 2* a loss inicial para equiparar en magnitud con las demas\n",
        "        loss_final = criterion(outputs[\"puntuación final\"].permute(0,2,1), labels[\"punt_final\"])\n",
        "        loss_cap = criterion(outputs[\"capitalización\"].permute(0,2,1), labels[\"capitalizacion\"])\n",
        "\n",
        "        # Pérdida total\n",
        "        loss = loss_inicial + loss_final + loss_cap\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping para evitar gradientes explosivos\n",
        "        nn_utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        total_loss_inicial += loss_inicial.item()\n",
        "        total_loss_final += loss_final.item()\n",
        "        total_loss_cap += loss_cap.item()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "    # VALIDACIÓN\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    val_loss_inicial = 0\n",
        "    val_loss_final = 0\n",
        "    val_loss_cap = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for embeddings, labels in val_loader:\n",
        "            embeddings = embeddings.to(device)\n",
        "            labels = {k: v.to(device) for k, v in labels.items()}\n",
        "\n",
        "            outputs = model(embeddings)\n",
        "\n",
        "            loss_inicial = 2*criterion(outputs[\"puntuación inicial\"].permute(0,2,1), labels[\"punt_inicial\"])  # le ponemos 2* a loss inicial para equiparar en magnitud con las demas\n",
        "\n",
        "            loss_final = criterion(outputs[\"puntuación final\"].permute(0,2,1), labels[\"punt_final\"])\n",
        "\n",
        "            loss_cap = criterion(outputs[\"capitalización\"].permute(0,2,1), labels[\"capitalizacion\"])\n",
        "\n",
        "            loss = loss_inicial + loss_final + loss_cap\n",
        "\n",
        "            total_val_loss += loss.item()\n",
        "            val_loss_inicial += loss_inicial.item()\n",
        "            val_loss_final += loss_final.item()\n",
        "            val_loss_cap += loss_cap.item()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "    # Actualizar learning rate\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    # Imprimir métricas detalladas\n",
        "    print(f\"Época {epoch+1}/{num_epochs}\")\n",
        "    print(f\"  Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "    print(f\"  Train - Inicial: {total_loss_inicial/len(train_loader):.4f}, Final: {total_loss_final/len(train_loader):.4f}, Cap: {total_loss_cap/len(train_loader):.4f}\")\n",
        "    print(f\"  Val   - Inicial: {val_loss_inicial/len(val_loader):.4f}, Final: {val_loss_final/len(val_loader):.4f}, Cap: {val_loss_cap/len(val_loader):.4f}\")\n",
        "    print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "\n",
        "    # Guardar cada epoca\n",
        "    ruta_epoca = f\"/content/drive/MyDrive/colab/modelosB/modelo_epoca_{epoch+1}.pt\"\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'val_loss': avg_val_loss,\n",
        "        }, ruta_epoca)\n",
        "\n",
        "\n",
        "    # Guardar mejor modelo\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0\n",
        "        ruta_mejor_modelo = \"/content/drive/MyDrive/colab/modelosB/mejor_modelo.pt\"\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'val_loss': avg_val_loss,\n",
        "        }, ruta_mejor_modelo)\n",
        "        print(f\"  ✓ Mejor modelo actualizado (Val Loss: {avg_val_loss:.4f})\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"  Sin mejora ({patience_counter}/{early_stop_patience})\")\n",
        "\n",
        "    # Early stopping\n",
        "    if patience_counter >= early_stop_patience:\n",
        "        print(f\"\\nEarly stopping en época {epoch+1}\")\n",
        "        break\n",
        "\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "\n",
        "print(f\"\\nEntrenamiento completado!\")\n",
        "print(f\"Mejor modelo guardado en: {ruta_mejor_modelo}\")\n",
        "print(f\"Mejor Val Loss: {best_val_loss:.4f}\")\n",
        "\n",
        "#Mostramos lo que printeo durante el entrenamiento\n",
        "\n",
        "\"\"\"\n",
        "Época 1/30\n",
        "  Train Loss: 1.3584 | Val Loss: 1.2807\n",
        "  Train - Inicial: 0.4258, Final: 0.4811, Cap: 0.4515\n",
        "  Val   - Inicial: 0.4152, Final: 0.4467, Cap: 0.4187\n",
        "  LR: 0.001000\n",
        "  ✓ Mejor modelo actualizado (Val Loss: 1.2807)\n",
        "------------------------------------------------------------\n",
        "Época 2/30\n",
        "  Train Loss: 1.2907 | Val Loss: 1.2589\n",
        "  Train - Inicial: 0.4165, Final: 0.4519, Cap: 0.4222\n",
        "  Val   - Inicial: 0.4133, Final: 0.4370, Cap: 0.4085\n",
        "  LR: 0.001000\n",
        "  ✓ Mejor modelo actualizado (Val Loss: 1.2589)\n",
        "------------------------------------------------------------\n",
        "Época 3/30\n",
        "  Train Loss: 1.2730 | Val Loss: 1.2504\n",
        "  Train - Inicial: 0.4148, Final: 0.4442, Cap: 0.4140\n",
        "  Val   - Inicial: 0.4126, Final: 0.4334, Cap: 0.4044\n",
        "  LR: 0.001000\n",
        "  ✓ Mejor modelo actualizado (Val Loss: 1.2504)\n",
        "------------------------------------------------------------\n",
        "Época 4/30\n",
        "  Train Loss: 1.2615 | Val Loss: 1.2464\n",
        "  Train - Inicial: 0.4136, Final: 0.4396, Cap: 0.4084\n",
        "  Val   - Inicial: 0.4120, Final: 0.4315, Cap: 0.4029\n",
        "  LR: 0.001000\n",
        "  ✓ Mejor modelo actualizado (Val Loss: 1.2464)\n",
        "------------------------------------------------------------\n",
        "Época 5/30\n",
        "  Train Loss: 1.2524 | Val Loss: 1.2430\n",
        "  Train - Inicial: 0.4128, Final: 0.4360, Cap: 0.4036\n",
        "  Val   - Inicial: 0.4117, Final: 0.4297, Cap: 0.4015\n",
        "  LR: 0.001000\n",
        "  ✓ Mejor modelo actualizado (Val Loss: 1.2430)\n",
        "------------------------------------------------------------\n",
        "Época 6/30\n",
        "  Train Loss: 1.2451 | Val Loss: 1.2428\n",
        "  Train - Inicial: 0.4120, Final: 0.4334, Cap: 0.3997\n",
        "  Val   - Inicial: 0.4117, Final: 0.4293, Cap: 0.4019\n",
        "  LR: 0.001000\n",
        "  ✓ Mejor modelo actualizado (Val Loss: 1.2428)\n",
        "------------------------------------------------------------\n",
        "Época 7/30\n",
        "  Train Loss: 1.2389 | Val Loss: 1.2419\n",
        "  Train - Inicial: 0.4113, Final: 0.4311, Cap: 0.3965\n",
        "  Val   - Inicial: 0.4115, Final: 0.4286, Cap: 0.4017\n",
        "  LR: 0.001000\n",
        "  ✓ Mejor modelo actualizado (Val Loss: 1.2419)\n",
        "------------------------------------------------------------\n",
        "Época 8/30\n",
        "  Train Loss: 1.2340 | Val Loss: 1.2425\n",
        "  Train - Inicial: 0.4107, Final: 0.4294, Cap: 0.3940\n",
        "  Val   - Inicial: 0.4114, Final: 0.4285, Cap: 0.4026\n",
        "  LR: 0.001000\n",
        "  Sin mejora (1/30)\n",
        "------------------------------------------------------------\n",
        "Época 9/30\n",
        "  Train Loss: 1.2293 | Val Loss: 1.2430\n",
        "  Train - Inicial: 0.4101, Final: 0.4276, Cap: 0.3917\n",
        "  Val   - Inicial: 0.4116, Final: 0.4287, Cap: 0.4026\n",
        "  LR: 0.001000\n",
        "  Sin mejora (2/30)\n",
        "------------------------------------------------------------\n",
        "Época 10/30\n",
        "  Train Loss: 1.2254 | Val Loss: 1.2444\n",
        "  Train - Inicial: 0.4096, Final: 0.4260, Cap: 0.3898\n",
        "  Val   - Inicial: 0.4118, Final: 0.4295, Cap: 0.4031\n",
        "  LR: 0.001000\n",
        "  Sin mejora (3/30)\n",
        "------------------------------------------------------------\n",
        "Época 11/30\n",
        "  Train Loss: 1.2221 | Val Loss: 1.2438\n",
        "  Train - Inicial: 0.4092, Final: 0.4247, Cap: 0.3883\n",
        "  Val   - Inicial: 0.4118, Final: 0.4289, Cap: 0.4031\n",
        "  LR: 0.000200\n",
        "  Sin mejora (4/30)\n",
        "------------------------------------------------------------\n",
        "Época 12/30\n",
        "  Train Loss: 1.2103 | Val Loss: 1.2445\n",
        "  Train - Inicial: 0.4075, Final: 0.4195, Cap: 0.3832\n",
        "  Val   - Inicial: 0.4119, Final: 0.4292, Cap: 0.4034\n",
        "  LR: 0.000200\n",
        "  Sin mejora (5/30)\n",
        "------------------------------------------------------------\n",
        "Época 13/30\n",
        "  Train Loss: 1.2064 | Val Loss: 1.2456\n",
        "  Train - Inicial: 0.4070, Final: 0.4178, Cap: 0.3816\n",
        "  Val   - Inicial: 0.4122, Final: 0.4294, Cap: 0.4040\n",
        "  LR: 0.000200\n",
        "  Sin mejora (6/30)\n",
        "------------------------------------------------------------\n",
        "Época 14/30\n",
        "  Train Loss: 1.2045 | Val Loss: 1.2464\n",
        "  Train - Inicial: 0.4067, Final: 0.4170, Cap: 0.3808\n",
        "  Val   - Inicial: 0.4123, Final: 0.4295, Cap: 0.4046\n",
        "  LR: 0.000200\n",
        "  Sin mejora (7/30)\n",
        "------------------------------------------------------------\n",
        "Época 15/30\n",
        "  Train Loss: 1.2027 | Val Loss: 1.2470\n",
        "  Train - Inicial: 0.4065, Final: 0.4161, Cap: 0.3801\n",
        "  Val   - Inicial: 0.4122, Final: 0.4299, Cap: 0.4048\n",
        "  LR: 0.000040\n",
        "  Sin mejora (8/30)\n",
        "------------------------------------------------------------\n",
        "Época 16/30\n",
        "  Train Loss: 1.1998 | Val Loss: 1.2487\n",
        "  Train - Inicial: 0.4061, Final: 0.4147, Cap: 0.3791\n",
        "  Val   - Inicial: 0.4128, Final: 0.4303, Cap: 0.4055\n",
        "  LR: 0.000040\n",
        "  Sin mejora (9/30)\n",
        "------------------------------------------------------------\n",
        "Época 17/30\n",
        "  Train Loss: 1.1990 | Val Loss: 1.2490\n",
        "  Train - Inicial: 0.4060, Final: 0.4143, Cap: 0.3788\n",
        "  Val   - Inicial: 0.4126, Final: 0.4304, Cap: 0.4060\n",
        "  LR: 0.000040\n",
        "  Sin mejora (10/30)\n",
        "------------------------------------------------------------\n",
        "Época 18/30\n",
        "  Train Loss: 1.1983 | Val Loss: 1.2492\n",
        "  Train - Inicial: 0.4058, Final: 0.4141, Cap: 0.3784\n",
        "  Val   - Inicial: 0.4127, Final: 0.4304, Cap: 0.4061\n",
        "  LR: 0.000040\n",
        "  Sin mejora (11/30)\n",
        "------------------------------------------------------------\n",
        "Época 19/30\n",
        "  Train Loss: 1.1979 | Val Loss: 1.2498\n",
        "  Train - Inicial: 0.4057, Final: 0.4139, Cap: 0.3783\n",
        "  Val   - Inicial: 0.4127, Final: 0.4308, Cap: 0.4063\n",
        "  LR: 0.000008\n",
        "  Sin mejora (12/30)\n",
        "------------------------------------------------------------\n",
        "Época 20/30\n",
        "  Train Loss: 1.1975 | Val Loss: 1.2496\n",
        "  Train - Inicial: 0.4056, Final: 0.4137, Cap: 0.3782\n",
        "  Val   - Inicial: 0.4127, Final: 0.4306, Cap: 0.4063\n",
        "  LR: 0.000008\n",
        "  Sin mejora (13/30)\n",
        "------------------------------------------------------------\n",
        "Época 21/30\n",
        "  Train Loss: 1.1973 | Val Loss: 1.2495\n",
        "  Train - Inicial: 0.4057, Final: 0.4136, Cap: 0.3781\n",
        "  Val   - Inicial: 0.4128, Final: 0.4306, Cap: 0.4062\n",
        "  LR: 0.000008\n",
        "  Sin mejora (14/30)\n",
        "------------------------------------------------------------\n",
        "Época 22/30\n",
        "  Train Loss: 1.1970 | Val Loss: 1.2499\n",
        "  Train - Inicial: 0.4057, Final: 0.4134, Cap: 0.3779\n",
        "  Val   - Inicial: 0.4128, Final: 0.4307, Cap: 0.4064\n",
        "  LR: 0.000008\n",
        "  Sin mejora (15/30)\n",
        "------------------------------------------------------------\n",
        "Época 23/30\n",
        "  Train Loss: 1.1972 | Val Loss: 1.2499\n",
        "  Train - Inicial: 0.4057, Final: 0.4135, Cap: 0.3779\n",
        "  Val   - Inicial: 0.4128, Final: 0.4307, Cap: 0.4065\n",
        "  LR: 0.000002\n",
        "  Sin mejora (16/30)\n",
        "------------------------------------------------------------\n",
        "Época 24/30\n",
        "  Train Loss: 1.1971 | Val Loss: 1.2499\n",
        "  Train - Inicial: 0.4057, Final: 0.4135, Cap: 0.3779\n",
        "  Val   - Inicial: 0.4127, Final: 0.4307, Cap: 0.4064\n",
        "  LR: 0.000002\n",
        "  Sin mejora (17/30)\n",
        "------------------------------------------------------------\n",
        "Época 25/30\n",
        "  Train Loss: 1.1970 | Val Loss: 1.2500\n",
        "  Train - Inicial: 0.4056, Final: 0.4134, Cap: 0.3779\n",
        "  Val   - Inicial: 0.4128, Final: 0.4308, Cap: 0.4064\n",
        "  LR: 0.000002\n",
        "  Sin mejora (18/30)\n",
        "------------------------------------------------------------\n",
        "Época 26/30\n",
        "  Train Loss: 1.1969 | Val Loss: 1.2500\n",
        "  Train - Inicial: 0.4056, Final: 0.4134, Cap: 0.3779\n",
        "  Val   - Inicial: 0.4128, Final: 0.4308, Cap: 0.4065\n",
        "  LR: 0.000002\n",
        "  Sin mejora (19/30)\n",
        "------------------------------------------------------------\n",
        "Época 27/30\n",
        "  Train Loss: 1.1969 | Val Loss: 1.2500\n",
        "  Train - Inicial: 0.4057, Final: 0.4134, Cap: 0.3779\n",
        "  Val   - Inicial: 0.4128, Final: 0.4308, Cap: 0.4064\n",
        "  LR: 0.000000\n",
        "  Sin mejora (20/30)\n",
        "------------------------------------------------------------\n",
        "Época 28/30\n",
        "  Train Loss: 1.1968 | Val Loss: 1.2500\n",
        "  Train - Inicial: 0.4056, Final: 0.4134, Cap: 0.3778\n",
        "  Val   - Inicial: 0.4128, Final: 0.4308, Cap: 0.4065\n",
        "  LR: 0.000000\n",
        "  Sin mejora (21/30)\n",
        "------------------------------------------------------------\n",
        "Época 29/30\n",
        "  Train Loss: 1.1969 | Val Loss: 1.2500\n",
        "  Train - Inicial: 0.4056, Final: 0.4134, Cap: 0.3779\n",
        "  Val   - Inicial: 0.4128, Final: 0.4308, Cap: 0.4065\n",
        "  LR: 0.000000\n",
        "  Sin mejora (22/30)\n",
        "------------------------------------------------------------\n",
        "Época 30/30\n",
        "  Train Loss: 1.1968 | Val Loss: 1.2500\n",
        "  Train - Inicial: 0.4056, Final: 0.4134, Cap: 0.3778\n",
        "  Val   - Inicial: 0.4128, Final: 0.4308, Cap: 0.4065\n",
        "  LR: 0.000000\n",
        "  Sin mejora (23/30)\n",
        "------------------------------------------------------------\n",
        "\n",
        "Entrenamiento completado!\n",
        "Mejor modelo guardado en: /content/drive/MyDrive/colab/modelosB/mejor_modelo.pt\n",
        "Mejor Val Loss: 1.2419\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ao6KGtwqezvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EVALUACIÓN DE MODELOS"
      ],
      "metadata": {
        "id": "tQ4v7GKIqK_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###EVALUACIÓN UNIDIRECCIONAL"
      ],
      "metadata": {
        "id": "AOMWXohoqPyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model = RNN_Unidireccional(embedding_dim=768, hidden_dim1=128, hidden_dim2=32,  num_layers=2, dropout=0.4)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "# ---------------------------------------\n",
        "# EVALUACIÓN SOBRE EL TEST SET\n",
        "# ---------------------------------------\n",
        "\n",
        "test_dataset = DynamicEmbeddingDataset(test_df.reset_index(drop=True), tokenizer, model_bert)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Cargar el mejor modelo\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/colab/modelosU/mejor_modelo.pt\") #modelosU para unidireccional\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "print(\"\\n=== Evaluando en TEST SET con mejor modelo Unidireccional ===\\n\")\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
        "\n",
        "total_test_loss = 0\n",
        "loss_init = 0\n",
        "loss_final = 0\n",
        "loss_cap = 0\n",
        "\n",
        "# Para F1\n",
        "all_true_init  = []\n",
        "all_pred_init  = []\n",
        "\n",
        "all_true_final = []\n",
        "all_pred_final = []\n",
        "\n",
        "all_true_cap   = []\n",
        "all_pred_cap   = []\n",
        "\n",
        "correct_init = 0\n",
        "correct_final = 0\n",
        "correct_cap = 0\n",
        "\n",
        "total_tokens = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for embeddings, labels in test_loader:\n",
        "        embeddings = embeddings.to(device)\n",
        "        labels = {k: v.to(device) for k, v in labels.items()}\n",
        "\n",
        "        outputs = model(embeddings)\n",
        "\n",
        "        # Loss\n",
        "        l_i = 2*criterion(outputs[\"puntuación inicial\"].permute(0,2,1), labels[\"punt_inicial\"]) # 2* para equipararla con las otras\n",
        "        l_f = criterion(outputs[\"puntuación final\"].permute(0,2,1), labels[\"punt_final\"])\n",
        "        l_c = criterion(outputs[\"capitalización\"].permute(0,2,1), labels[\"capitalizacion\"])\n",
        "\n",
        "        loss = l_i + l_f + l_c\n",
        "\n",
        "        total_test_loss += loss.item()\n",
        "        loss_init += l_i.item()\n",
        "        loss_final += l_f.item()\n",
        "        loss_cap += l_c.item()\n",
        "\n",
        "        # Predicciones (batch, seq)\n",
        "        pred_init = outputs[\"puntuación inicial\"].argmax(dim=-1)\n",
        "        pred_final = outputs[\"puntuación final\"].argmax(dim=-1)\n",
        "        pred_cap = outputs[\"capitalización\"].argmax(dim=-1)\n",
        "\n",
        "        mask = (labels[\"punt_inicial\"] != -100)\n",
        "\n",
        "        # Guardar para F1\n",
        "        all_true_init.extend(labels[\"punt_inicial\"][mask].cpu().tolist())\n",
        "        all_pred_init.extend(pred_init[mask].cpu().tolist())\n",
        "\n",
        "        all_true_final.extend(labels[\"punt_final\"][mask].cpu().tolist())\n",
        "        all_pred_final.extend(pred_final[mask].cpu().tolist())\n",
        "\n",
        "        all_true_cap.extend(labels[\"capitalizacion\"][mask].cpu().tolist())\n",
        "        all_pred_cap.extend(pred_cap[mask].cpu().tolist())\n",
        "\n",
        "        # Accuracy por tarea\n",
        "        # PREDICCIONES → (batch, seq, clases)\n",
        "        pred_init = outputs[\"puntuación inicial\"].argmax(dim=-1)\n",
        "        pred_final = outputs[\"puntuación final\"].argmax(dim=-1)\n",
        "        pred_cap = outputs[\"capitalización\"].argmax(dim=-1)\n",
        "\n",
        "        mask = (labels[\"punt_inicial\"] != -100)\n",
        "\n",
        "        correct_init += ((pred_init == labels[\"punt_inicial\"]) * mask).sum().item()\n",
        "        correct_final += ((pred_final == labels[\"punt_final\"]) * mask).sum().item()\n",
        "        correct_cap += ((pred_cap == labels[\"capitalizacion\"]) * mask).sum().item()\n",
        "\n",
        "        total_tokens += mask.sum().item()\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "#   CÁLCULO DE F1 MACRO\n",
        "# ----------------------------\n",
        "\n",
        "# Puntuación inicial: 2 clases → ¿, \"\"\n",
        "f1_init = f1_score(all_true_init, all_pred_init, average=\"macro\")\n",
        "\n",
        "# Puntuación final: 4 clases → ,  .  ?  \"\"\n",
        "f1_final = f1_score(all_true_final, all_pred_final, average=\"macro\")\n",
        "\n",
        "# Capitalización: 4 clases → 0 1 2 3\n",
        "f1_cap = f1_score(all_true_cap, all_pred_cap, average=\"macro\")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "#     PRINT RESULTADOS\n",
        "# ----------------------------\n",
        "print(\"\\n===== RESULTADOS TEST =====\")\n",
        "print(f\"Test Loss Total: {total_test_loss / len(test_loader):.4f}\")\n",
        "print(f\"  Inicial: {loss_init / len(test_loader):.4f}\")\n",
        "print(f\"  Final  : {loss_final / len(test_loader):.4f}\")\n",
        "print(f\"  Capital: {loss_cap / len(test_loader):.4f}\")\n",
        "\n",
        "print(\"\\n===== F1 MACRO =====\")\n",
        "print(f\"  Puntuación inicial (¿, \\\"\\\"): {f1_init:.4f}\")\n",
        "print(f\"  Puntuación final   (,, ., ?, \\\"\\\"): {f1_final:.4f}\")\n",
        "print(f\"  Capitalización     (0,1,2,3): {f1_cap:.4f}\")\n",
        "\n",
        "print(\"\\n===== ACCURACY =====\")\n",
        "print(f\" Inicial: {correct_init / total_tokens:.4f}\")\n",
        "print(f\" Final : {correct_final / total_tokens:.4f}\")\n",
        "print(f\" Capital: {correct_cap / total_tokens:.4f}\")\n",
        "\n",
        "# Mostramos lo que printeo\n",
        "\"\"\"\n",
        "=== Evaluando en TEST SET con mejor modelo Unidireccional ===\n",
        "\n",
        "\n",
        "===== RESULTADOS TEST =====\n",
        "Test Loss Total: 0.6204\n",
        "  Inicial: 0.1444\n",
        "  Final  : 0.3020\n",
        "  Capital: 0.1741\n",
        "\n",
        "===== F1 MACRO =====\n",
        "  Puntuación inicial (¿, \"\"): 0.7869\n",
        "  Puntuación final   (,, ., ?, \"\"): 0.3820\n",
        "  Capitalización     (0,1,2,3): 0.7420\n",
        "\n",
        "===== ACCURACY =====\n",
        " Inicial: 0.9920\n",
        " Final : 0.9171\n",
        " Capital: 0.9658\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NygS9JcBqNwE",
        "outputId": "8933b15e-547d-4535-8dad-e94fc1999ce3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Evaluando en TEST SET con mejor modelo Unidireccional ===\n",
            "\n",
            "\n",
            "===== RESULTADOS TEST =====\n",
            "Test Loss Total: 0.6204\n",
            "  Inicial: 0.1444\n",
            "  Final  : 0.3020\n",
            "  Capital: 0.1741\n",
            "\n",
            "===== F1 MACRO =====\n",
            "  Puntuación inicial (¿, \"\"): 0.7869\n",
            "  Puntuación final   (,, ., ?, \"\"): 0.3820\n",
            "  Capitalización     (0,1,2,3): 0.7420\n",
            "\n",
            "===== ACCURACY =====\n",
            " Inicial: 0.9920\n",
            " Final : 0.9171\n",
            " Capital: 0.9658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###EVALUACIÓN BIDIRECCIONAL\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p0xtKHht1vht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model = RNN_Bidireccional(embedding_dim=768, hidden_dim1=128, hidden_dim2=32,  num_layers=2, dropout=0.4)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "# ---------------------------------------\n",
        "# EVALUACIÓN SOBRE EL TEST SET\n",
        "# ---------------------------------------\n",
        "\n",
        "test_dataset = DynamicEmbeddingDataset(test_df.reset_index(drop=True), tokenizer, model_bert)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Cargar el mejor modelo\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/colab/modelosB/mejor_modelo.pt\") #modelosB para bidireccional\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "print(\"\\n=== Evaluando en TEST SET con mejor modelo Bidireccional ===\\n\")\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
        "\n",
        "total_test_loss = 0\n",
        "loss_init = 0\n",
        "loss_final = 0\n",
        "loss_cap = 0\n",
        "\n",
        "# Para F1\n",
        "all_true_init  = []\n",
        "all_pred_init  = []\n",
        "\n",
        "all_true_final = []\n",
        "all_pred_final = []\n",
        "\n",
        "all_true_cap   = []\n",
        "all_pred_cap   = []\n",
        "\n",
        "correct_init = 0\n",
        "correct_final = 0\n",
        "correct_cap = 0\n",
        "\n",
        "total_tokens = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for embeddings, labels in test_loader:\n",
        "        embeddings = embeddings.to(device)\n",
        "        labels = {k: v.to(device) for k, v in labels.items()}\n",
        "\n",
        "        outputs = model(embeddings)\n",
        "\n",
        "        # Loss\n",
        "        l_i = 2*criterion(outputs[\"puntuación inicial\"].permute(0,2,1), labels[\"punt_inicial\"]) # 2* para equipararla con las otras\n",
        "        l_f = criterion(outputs[\"puntuación final\"].permute(0,2,1), labels[\"punt_final\"])\n",
        "        l_c = criterion(outputs[\"capitalización\"].permute(0,2,1), labels[\"capitalizacion\"])\n",
        "\n",
        "        loss = l_i + l_f + l_c\n",
        "\n",
        "        total_test_loss += loss.item()\n",
        "        loss_init += l_i.item()\n",
        "        loss_final += l_f.item()\n",
        "        loss_cap += l_c.item()\n",
        "\n",
        "        # Predicciones (batch, seq)\n",
        "        pred_init = outputs[\"puntuación inicial\"].argmax(dim=-1)\n",
        "        pred_final = outputs[\"puntuación final\"].argmax(dim=-1)\n",
        "        pred_cap = outputs[\"capitalización\"].argmax(dim=-1)\n",
        "\n",
        "        mask = (labels[\"punt_inicial\"] != -100)\n",
        "\n",
        "        # Guardar para F1\n",
        "        all_true_init.extend(labels[\"punt_inicial\"][mask].cpu().tolist())\n",
        "        all_pred_init.extend(pred_init[mask].cpu().tolist())\n",
        "\n",
        "        all_true_final.extend(labels[\"punt_final\"][mask].cpu().tolist())\n",
        "        all_pred_final.extend(pred_final[mask].cpu().tolist())\n",
        "\n",
        "        all_true_cap.extend(labels[\"capitalizacion\"][mask].cpu().tolist())\n",
        "        all_pred_cap.extend(pred_cap[mask].cpu().tolist())\n",
        "\n",
        "        # Accuracy por tarea\n",
        "        # PREDICCIONES → (batch, seq, clases)\n",
        "        pred_init = outputs[\"puntuación inicial\"].argmax(dim=-1)\n",
        "        pred_final = outputs[\"puntuación final\"].argmax(dim=-1)\n",
        "        pred_cap = outputs[\"capitalización\"].argmax(dim=-1)\n",
        "\n",
        "        mask = (labels[\"punt_inicial\"] != -100)\n",
        "\n",
        "        correct_init += ((pred_init == labels[\"punt_inicial\"]) * mask).sum().item()\n",
        "        correct_final += ((pred_final == labels[\"punt_final\"]) * mask).sum().item()\n",
        "        correct_cap += ((pred_cap == labels[\"capitalizacion\"]) * mask).sum().item()\n",
        "\n",
        "        total_tokens += mask.sum().item()\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "#   CÁLCULO DE F1 MACRO\n",
        "# ----------------------------\n",
        "\n",
        "# Puntuación inicial: 2 clases → ¿, \"\"\n",
        "f1_init = f1_score(all_true_init, all_pred_init, average=\"macro\")\n",
        "\n",
        "# Puntuación final: 4 clases → ,  .  ?  \"\"\n",
        "f1_final = f1_score(all_true_final, all_pred_final, average=\"macro\")\n",
        "\n",
        "# Capitalización: 4 clases → 0 1 2 3\n",
        "f1_cap = f1_score(all_true_cap, all_pred_cap, average=\"macro\")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "#     PRINT RESULTADOS\n",
        "# ----------------------------\n",
        "print(\"\\n===== RESULTADOS TEST =====\")\n",
        "print(f\"Test Loss Total: {total_test_loss / len(test_loader):.4f}\")\n",
        "print(f\"  Inicial: {loss_init / len(test_loader):.4f}\")\n",
        "print(f\"  Final  : {loss_final / len(test_loader):.4f}\")\n",
        "print(f\"  Capital: {loss_cap / len(test_loader):.4f}\")\n",
        "\n",
        "print(\"\\n===== F1 MACRO =====\")\n",
        "print(f\"  Puntuación inicial (¿, \\\"\\\"): {f1_init:.4f}\")\n",
        "print(f\"  Puntuación final   (,, ., ?, \\\"\\\"): {f1_final:.4f}\")\n",
        "print(f\"  Capitalización     (0,1,2,3): {f1_cap:.4f}\")\n",
        "\n",
        "print(\"\\n===== ACCURACY =====\")\n",
        "print(f\" Inicial: {correct_init / total_tokens:.4f}\")\n",
        "print(f\" Final : {correct_final / total_tokens:.4f}\")\n",
        "print(f\" Capital: {correct_cap / total_tokens:.4f}\")\n",
        "\n",
        "# Mostramos lo que printeo\n",
        "\"\"\"\n",
        "=== Evaluando en TEST SET con mejor modelo Bidireccional ===\n",
        "\n",
        "\n",
        "===== RESULTADOS TEST =====\n",
        "Test Loss Total: 0.4457\n",
        "  Inicial: 0.1223\n",
        "  Final  : 0.1812\n",
        "  Capital: 0.1423\n",
        "\n",
        "===== F1 MACRO =====\n",
        "  Puntuación inicial (¿, \"\"): 0.9208\n",
        "  Puntuación final   (,, ., ?, \"\"): 0.7996\n",
        "  Capitalización     (0,1,2,3): 0.8125\n",
        "\n",
        "===== ACCURACY =====\n",
        " Inicial: 0.9963\n",
        " Final : 0.9574\n",
        " Capital: 0.9762\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "q4tmUjMF1hGQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8542ef0-c683-43a0-bbf8-2b469a49962b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Evaluando en TEST SET con mejor modelo Bidireccional ===\n",
            "\n",
            "\n",
            "===== RESULTADOS TEST =====\n",
            "Test Loss Total: 0.4457\n",
            "  Inicial: 0.1223\n",
            "  Final  : 0.1812\n",
            "  Capital: 0.1423\n",
            "\n",
            "===== F1 MACRO =====\n",
            "  Puntuación inicial (¿, \"\"): 0.9208\n",
            "  Puntuación final   (,, ., ?, \"\"): 0.7996\n",
            "  Capitalización     (0,1,2,3): 0.8125\n",
            "\n",
            "===== ACCURACY =====\n",
            " Inicial: 0.9963\n",
            " Final : 0.9574\n",
            " Capital: 0.9762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PREDICCIONES CON EL MEJOR MODELO (BIDIRECCIONAL)"
      ],
      "metadata": {
        "id": "glQt__qmNvuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN_Bidireccional(embedding_dim=768, hidden_dim1=128, hidden_dim2=32,  num_layers=2, dropout=0.4)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "# Cargar mejor modelo\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/colab/modelosB/mejor_modelo.pt\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/datos_test.csv\")\n",
        "\n",
        "# Agrupar tokens por párrafo\n",
        "test_df = df_test.groupby(\"instancia_id\").agg({\n",
        "    \"token_id\": list,\n",
        "    \"token\": list,\n",
        "    \"punt_inicial\": list,\n",
        "    \"punt_final\": list,\n",
        "    \"capitalización\": list\n",
        "}).reset_index()\n",
        "\n",
        "pred_dataset = DynamicEmbeddingDataset(test_df.reset_index(drop=True), tokenizer, model_bert, modo = \"pred\")\n",
        "pred_loader = DataLoader(pred_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "pred_inicial = []\n",
        "pred_final = []\n",
        "pred_cap = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (embeddings, _) in enumerate(pred_loader):\n",
        "        embeddings = embeddings.to(device)\n",
        "        outputs = model(embeddings)\n",
        "\n",
        "        pred_init  = outputs[\"puntuación inicial\"].argmax(dim=-1).cpu()\n",
        "        pred_fin   = outputs[\"puntuación final\"].argmax(dim=-1).cpu()\n",
        "        pred_capit = outputs[\"capitalización\"].argmax(dim=-1).cpu()\n",
        "\n",
        "        # Para cada párrafo dentro del batch\n",
        "        for i in range(pred_init.shape[0]):\n",
        "            # largo real del párrafo (sin padding)\n",
        "            real_len = len(test_df.loc[len(pred_inicial), \"token\"])\n",
        "\n",
        "            pred_inicial.append(pred_init[i][:real_len].tolist())\n",
        "            pred_final.append(pred_fin[i][:real_len].tolist())\n",
        "            pred_cap.append(pred_capit[i][:real_len].tolist())\n",
        "\n",
        "# Expandir listas de listas (párrafos) a 1 pred por token\n",
        "df_test[\"punt_inicial\"]     = [p for par in pred_inicial for p in par]\n",
        "df_test[\"punt_final\"]       = [p for par in pred_final   for p in par]\n",
        "df_test[\"capitalización\"]   = [p for par in pred_cap     for p in par]\n",
        "\n",
        "ruta_salida = \"/content/drive/MyDrive/colab/predicciones_test.csv\"\n",
        "df_test.to_csv(ruta_salida, index=False)\n",
        "\n",
        "print(f\"\\nPredicciones generadas correctamente y guardadas en:\\n{ruta_salida}\")\n"
      ],
      "metadata": {
        "id": "G5OfP2mJPf4f",
        "outputId": "6d34a964-b395-4200-b91f-8bc7da664656",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicciones generadas correctamente y guardadas en:\n",
            "/content/drive/MyDrive/colab/predicciones_test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##OTROS"
      ],
      "metadata": {
        "id": "uJTN0UQZ1pyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predecir_parrafo(texto, modelo, tokenizer, bert_model, device):\n",
        "    \"\"\"\n",
        "    Recibe un párrafo de texto y devuelve las predicciones de puntuación y capitalización.\n",
        "\n",
        "    Args:\n",
        "        texto: string con el texto a procesar\n",
        "        modelo: modelo entrenado\n",
        "        tokenizer: tokenizer de BERT\n",
        "        bert_model: modelo BERT para embeddings\n",
        "        device: 'cuda' o 'cpu'\n",
        "\n",
        "    Returns:\n",
        "        dict con tokens y sus predicciones\n",
        "    \"\"\"\n",
        "    modelo.eval()\n",
        "\n",
        "    # Tokenizar el texto\n",
        "    tokens = tokenizer.tokenize(texto)\n",
        "\n",
        "    # Obtener embeddings\n",
        "    token_embeddings = []\n",
        "    for token in tokens:\n",
        "        token_id = tokenizer.convert_tokens_to_ids(token)\n",
        "        if token_id is None or token_id == tokenizer.unk_token_id:\n",
        "            token_id = tokenizer.unk_token_id\n",
        "        emb = bert_model.embeddings.word_embeddings.weight[token_id].detach()\n",
        "        token_embeddings.append(emb)\n",
        "\n",
        "    # Convertir a tensor y añadir dimensión de batch\n",
        "    embeddings = torch.stack(token_embeddings).unsqueeze(0).to(device)  # (1, seq_len, 768)\n",
        "\n",
        "    # Hacer predicción\n",
        "    with torch.no_grad():\n",
        "        outputs = modelo(embeddings)\n",
        "\n",
        "    # Obtener las clases predichas\n",
        "    punt_inicial_pred = torch.argmax(outputs[\"puntuación inicial\"], dim=-1).squeeze().cpu().numpy()\n",
        "    punt_final_pred = torch.argmax(outputs[\"puntuación final\"], dim=-1).squeeze().cpu().numpy()\n",
        "    capital_pred = torch.argmax(outputs[\"capitalización\"], dim=-1).squeeze().cpu().numpy()\n",
        "\n",
        "    # Mapeos de clases a etiquetas legibles\n",
        "    punt_inicial_map = {0: \"Sin puntuación\", 1: \"Con puntuación\"}\n",
        "    punt_final_map = {0: \"Ninguna\", 1: \"Punto\", 2: \"Coma\", 3: \"Otro\"}\n",
        "    capital_map = {0: \"Minúscula\", 1: \"Primera mayúscula\", 2: \"Todo mayúsculas\", 3: \"Otro\"}\n",
        "\n",
        "    # Crear resultado\n",
        "    resultados = []\n",
        "    for i, token in enumerate(tokens):\n",
        "        resultados.append({\n",
        "            \"token\": token,\n",
        "            \"puntuación_inicial\": punt_inicial_map.get(int(punt_inicial_pred[i]), \"Desconocido\"),\n",
        "            \"puntuación_final\": punt_final_map.get(int(punt_final_pred[i]), \"Desconocido\"),\n",
        "            \"capitalización\": capital_map.get(int(capital_pred[i]), \"Desconocido\")\n",
        "        })\n",
        "\n",
        "    return resultados\n",
        "\n",
        "def reconstruir_texto(resultados):\n",
        "    \"\"\"\n",
        "    Reconstruye el texto con puntuación y capitalización a partir de las predicciones.\n",
        "    \"\"\"\n",
        "    texto_reconstruido = \"\"\n",
        "\n",
        "    for resultado in resultados:\n",
        "        token = resultado[\"token\"]\n",
        "\n",
        "        # Aplicar capitalización\n",
        "        if resultado[\"capitalización\"] == \"Primera mayúscula\":\n",
        "            token = token.capitalize()\n",
        "        elif resultado[\"capitalización\"] == \"Todo mayúsculas\":\n",
        "            token = token.upper()\n",
        "\n",
        "        # Añadir puntuación inicial\n",
        "        if resultado[\"puntuación_inicial\"] == \"Con puntuación\":\n",
        "            # Aquí podrías decidir qué puntuación añadir (ej. ¿, ¡, etc.)\n",
        "            pass\n",
        "\n",
        "        # Añadir el token\n",
        "        if token.startswith(\"##\"):\n",
        "            texto_reconstruido += token[2:]\n",
        "        else:\n",
        "            if texto_reconstruido:\n",
        "                texto_reconstruido += \" \" + token\n",
        "            else:\n",
        "                texto_reconstruido += token\n",
        "\n",
        "        # Añadir puntuación final\n",
        "        if resultado[\"puntuación_final\"] == \"Punto\":\n",
        "            texto_reconstruido += \".\"\n",
        "        elif resultado[\"puntuación_final\"] == \"Coma\":\n",
        "            texto_reconstruido += \",\"\n",
        "\n",
        "    return texto_reconstruido"
      ],
      "metadata": {
        "id": "jKz-D7Vl_C8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cargar el mejor modelo\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Cargando el mejor modelo...\")\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/modelos/modelo_final_30e.pt\", map_location=device)\n",
        "modelo_cargado = ModeloUnidireccional(embedding_dim=768, hidden_dim=256, num_layers=2, dropout=0.3)\n",
        "modelo_cargado.load_state_dict(checkpoint['model_state_dict'])\n",
        "modelo_cargado = modelo_cargado.to(device)\n",
        "print(f\"Modelo cargado (época {checkpoint['epoch']}, val_loss: {checkpoint['val_loss']:.4f})\")\n",
        "\n",
        "# Ejemplo de uso\n",
        "texto_ejemplo = \"había perdido la esperanza pero seguía creyendo porque sabía que era un tenista demasiado bueno para no ganar también aquí pero no me he alegrado cuando  ha perdido lo respeto demasiado estabas nervioso antes de la final\"\n",
        "print(f\"\\nTexto de entrada: '{texto_ejemplo}'\\n\")\n",
        "\n",
        "predicciones = predecir_parrafo(texto_ejemplo, modelo_cargado, tokenizer, model_bert, device)\n",
        "\n",
        "# Mostrar predicciones detalladas\n",
        "print(\"Predicciones por token:\")\n",
        "print(\"-\" * 80)\n",
        "for pred in predicciones:\n",
        "    print(f\"Token: {pred['token']:15s} | Punt. Inicial: {pred['puntuación_inicial']:20s} | \"\n",
        "          f\"Punt. Final: {pred['puntuación_final']:10s} | Cap: {pred['capitalización']}\")\n",
        "\n",
        "# Reconstruir texto\n",
        "texto_reconstruido = reconstruir_texto(predicciones)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(f\"Texto reconstruido: '{texto_reconstruido}'\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGf4pyY9_JId",
        "outputId": "4c3cceca-4de6-4ecf-bed3-ec12bc240a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando el mejor modelo...\n",
            "Modelo cargado (época 29, val_loss: 0.3581)\n",
            "\n",
            "Texto de entrada: 'había perdido la esperanza pero seguía creyendo porque sabía que era un tenista demasiado bueno para no ganar también aquí pero no me he alegrado cuando rafa ha perdido lo respeto demasiado estabas nervioso antes de la final'\n",
            "\n",
            "Predicciones por token:\n",
            "--------------------------------------------------------------------------------\n",
            "Token: había           | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Primera mayúscula\n",
            "Token: perdido         | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: la              | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: esperanza       | Punt. Inicial: Sin puntuación       | Punt. Final: Coma       | Cap: Minúscula\n",
            "Token: pero            | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: seg             | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: ##uía           | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: c               | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: ##rey           | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: ##endo          | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: porque          | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: sa              | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: ##bía           | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: que             | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: era             | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: un              | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: tenis           | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: ##ta            | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: demasiado       | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: buen            | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: ##o             | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: para            | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: no              | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: ganar           | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: también         | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: aquí            | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: pero            | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Primera mayúscula\n",
            "Token: no              | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: me              | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: he              | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: ale             | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: ##grado         | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: cuando          | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: ra              | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: ##fa            | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Primera mayúscula\n",
            "Token: ha              | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: perdido         | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: lo              | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: resp            | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: ##eto           | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: demasiado       | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: estaba          | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Primera mayúscula\n",
            "Token: ##s             | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Primera mayúscula\n",
            "Token: ner             | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: ##vios          | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: ##o             | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: antes           | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: de              | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: la              | Punt. Inicial: Sin puntuación       | Punt. Final: Ninguna    | Cap: Minúscula\n",
            "Token: final           | Punt. Inicial: Sin puntuación       | Punt. Final: Punto      | Cap: Minúscula\n",
            "\n",
            "================================================================================\n",
            "Texto reconstruido: 'Había perdido la esperanza, pero seguía creyendo porque sabía que era un tenista demasiado bueno para no ganar también aquí Pero no me he alegrado cuando rafa ha perdido lo respeto demasiado Estabas nervioso antes de la final.'\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reconstruccion_texto(dataSet): #data set con columnas: instancia_id (cte), token_id, token, capitalización, punt_inicial, punt_final\n",
        "  frase = ''\n",
        "  frase_final = ''\n",
        "  n = dataSet.shape[0]\n",
        "  i = 0\n",
        "  capitalizaciones = []\n",
        "  punt_finales = []\n",
        "  punt_iniciales = []\n",
        "\n",
        "  for fila in dataSet.iterrows():\n",
        "    subpalabra = fila[1]['token']\n",
        "\n",
        "    if subpalabra[:2] == '##':\n",
        "      subpalabra = subpalabra[2:]\n",
        "    else:\n",
        "      capitalizaciones.append(fila[1]['capitalización'])\n",
        "      punt_iniciales.append(fila[1]['punt_inicial'])\n",
        "\n",
        "    if i == n-1:\n",
        "      frase += subpalabra\n",
        "      punt_finales.append(fila[1]['punt_final'])\n",
        "    else:\n",
        "      if dataSet.iloc[i+1]['token'][:2] == '##':\n",
        "        frase += subpalabra\n",
        "      else:\n",
        "        frase += subpalabra + ' '\n",
        "        punt_finales.append(fila[1]['punt_final'])\n",
        "    i +=1\n",
        "\n",
        "  palabras = frase.split()\n",
        "  for i, palabra in enumerate(palabras):\n",
        "\n",
        "    if punt_iniciales[i] == 1:\n",
        "      frase_final += '¿'\n",
        "\n",
        "    if capitalizaciones[i] == 0:\n",
        "      frase_final += palabra\n",
        "    elif capitalizaciones[i] == 1:\n",
        "      frase_final += palabra.capitalize()\n",
        "    elif capitalizaciones[i] == 3:\n",
        "      frase_final += palabra.upper()\n",
        "    else:\n",
        "      frase_final += palabra[:-1].capitalize() + palabra[-1].upper()\n",
        "\n",
        "    if punt_finales[i] == 1:\n",
        "      frase_final += '.'\n",
        "    elif punt_finales[i] == 2:\n",
        "      frase_final += ','\n",
        "    elif punt_finales[i] == 3:\n",
        "      frase_final += '?'\n",
        "\n",
        "\n",
        "\n",
        "    if i != len(palabras) - 1 and palabras[i+1] != \"'\" and palabras[i] != \"'\":\n",
        "        frase_final += ' '\n",
        "\n",
        "  return frase_final"
      ],
      "metadata": {
        "id": "m56_uOtIfLQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,100):\n",
        "  print(reconstruccion_texto(df_test[df_test[\"instancia_id\"]==i]))"
      ],
      "metadata": {
        "id": "SpbZtikvfMrQ",
        "outputId": "4be15cad-1e37-4cb6-d054-82bdcd50e4fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En cambio, el mismo alumnado está obteniendo unos resultados por encima de la media española en lo que se refiere al castellano, y si no los obtuviera, no se preocupe porque tomaríamos las oportunas medidas para que eso fuese así.\n",
            "No, nos extraña. Lo conocemos perfectamente.\n",
            "Y en el mes de abril hay una orden un mandato de este parlamento, exactamente para lo mismo aprobado sin ningún voto en contra señorías.\n",
            "No olviden para acabar todos los que componen esta cámara, que cuando pocos de aquí muy pocos hace años confiaban en que la ley y la policía acabarían con los comandos. Nosotros sí, lo creíamos.\n",
            "En cambio, sí se sabe de la transferencia porque la ha conseguido Euzko Alderdi, jeltzalea.\n",
            "Claro, ¿y eso es bueno?\n",
            "Pero hasta aquí llegaba la coherencia de las propuestas del Partido Popular.\n",
            "Solo, incrementando también la red de atención a las personas de la tercera edad, podremos cubrir la necesidad de su asistencia sin que esta recaiga como pasa hoy en día, fundamentalmente en las mujeres.\n",
            "Entonces pusimos de manifiesto. ¿Qué es lo que cabe esperar de Eitb como televisión pública que se paga con el dinero de todos los vascos que sea un medio de comunicación en el que todos, cualquiera que sea nuestra ideología nos sentamos representados?\n",
            "Todo ello, por razón de la solidaridad del conjunto de la sociedad española, con quienes sufren la acción directa de una violencia que va dirigida realmente contra toda la sociedad y contra el estado de derecho.\n",
            "En segundo lugar, porque con la normativa fiscal que les es de aplicación se utilizan como instrumentos de elusión fiscal.\n",
            "Y ustedes han aprobado los presupuestos este año y el anterior y del anterior, pero bueno este año?\n",
            "Es un sistema en el que las rentas de capital pagan mucho menos que las rentas de trabajo. y eso es injusto.\n",
            "Gracias a la reforma de la ley orgánica del poder judicial impulsada por la mayoría absoluta del Partido Popular. esto se va a acabar porque el partido popular ha decidido liquidar la justicia universal.\n",
            "Mire, señor reyes, no se lo he dicho en la primera intervención, porque me he querido referir a otras cuestiones. Pero no se puede venir con tanto cinismo a esta tribuna.\n",
            "Y lo hace incorporando límites en su ejercicio.\n",
            "Somos parlamentarios y me parece razonable que aquí cada cual defienda en forma de moción o de PNL, porque no tenemos otra cuáles son las medidas que cada cual considera que son necesarias poner en marcha?\n",
            "Se lo preguntaba al partido Nacionalista vasco, que era el objeto.\n",
            "Es un problema de que ustedes se han querido colocar intencionada y deliberadamente en una determinada posición política. y cuando todo se mueve en este país, ustedes no quieren moverse.\n",
            "Y no se pueden poner condiciones porque igual he entendido yo mal, pero a mí me ha quedado la sensación de que cuando usted estaba hablando de lo que debería o no debería figurar en ese texto, según su criterio, daba la impresión de que usted estaba poniendo condiciones para mantener el fin de eta y para mantener la situación que tenemos ahora.\n",
            "Porque estimamos que siempre que se dé un incremento en los presupuestos destinados a educación nos parecerá bien y creo que la comunidad educativa lo recibirá de forma positiva.\n",
            "Por lo tanto, y por todo ello votaré a favor de la transaccional que el resto de grupos han firmado.\n",
            "Bien habla nuevamente de la mecánica, una vez aprobados los presupuestos y creemos perfectamente que se define aquí ya una atención singularizada caso, por caso, a la hora de hablar de los presupuestos de los centros educativos.\n",
            "¿Por qué traemos esta iniciativa?\n",
            "¿No se justifica que el precepto constitucional que manda establecer un equilibrio entre protección ambiental y defensa de intereses económicos, oscile caprichosamente al albur de intereses particulares o de intereses generales, no debidamente expuestos?\n",
            "No lo hacía, por supuesto, el régimen, nada más lejos, pero había quien desde dentro lo hacía.\n",
            "Creo que esta tarde hay una reunión del patronato o mañana. Creo que en breve va a ver una reunión del patronato y deberían ponerse negro sobre blanco requisitos de excelencia.\n",
            "Una es el cambio climático, otra el no al fracking y otra el sí a las renovables.\n",
            "Y como decimos ya desde ese momento incertidumbre\n",
            "De todas formas, como le digo, me voy contenta por el hecho de que esta iniciativa va a salir con una amplia mayoría, pero me voy profundamente preocupada.\n",
            "Proponemos también instar a las juntas generales o a las diputaciones forales a aplicar estrictamente su normativa foral del Irpf en lo que se refiere al tratamiento de los rendimientos de trabajo generados en un periodo superior a dos años, y no se obtengan de forma periódica o recurrente, evitando interpretaciones ventajosas de dicha normativa para determinados grupos profesionales.\n",
            "Por último, queremos señalar que en la lucha contra el Dopaje son fundamentales, las medidas de prevención y para ponerlas en práctica es imprescindible la dotación de un presupuesto económico y una asignación anual para el desarrollo de estas medidas relacionadas con la prevención, la investigación y el desarrollo de nuevas actividades preventivas contra el dopaje en todos los niveles deportivos.\n",
            "Ustedes, por lo tanto, han hecho otra vez el más espantoso de los ridículos y se han puesto en evidencia ante el resto de parlamentarios democráticos presentes en esta cámara.\n",
            "Y podríamos estar de acuerdo y estamos de acuerdo en que se inste a este gobierno a elaborar en el plazo que corresponda un plan para la deslegitimación ética social y política del terrorismo.\n",
            "Señorías, yo creo que estos elementos deben hacer reflexionar al gobierno que es lo que le vamos a pedir en nuestra moción.\n",
            "Y lo respetamos como respetamos el camino que ahora han adoptado. Pero nosotros somos singulares y somos singulares tanto en el Estado español como en Europa.\n",
            "Ustedes presentaron una propuesta en la ponencia de autogobierno. Nos ha dicho?\n",
            "Entonces nos gustaría saber con qué idea previa con qué enfoque con qué liderazgo aborda el gobierno vasco esta cuestión para luego enriquecerla con los aportes de las asociaciones de la sociedad civil, etcétera.\n",
            "Y también estarán junto a la placa de Fernando Buesa, un abogado que dejó su despacho para poner orden en la educación pública en este país, que integró a las Ikastolas y que tenía una profunda vocación de servicio público, y su vida fue reventada por unos asesinos que quisieron impedir que hoy estuviéramos aquí gentes diversas de orígenes diversos, representando a una ciudadanía diversa.\n",
            "Una disfunción una pérdida de tiempo para el alumnado y desde luego un gasto adicional para la administración.\n",
            "Señorías, habiendo hecho la explicación de lo que es el compromiso en el programa de gobierno que no es cerrado, sino que también estamos dispuestos a escuchar como estamos tomando referencia de las iniciativas que los grupos parlamentarios de la oposición estiman pertinentes, siendo que algunas de ellas ya están insertadas en nuestros planteamientos en el programa legislativo, y siendo también que no estamos nosotros como gobierno para echar por la borda trabajos anteriores, seremos receptivos, desde luego a lo que haya sido el esfuerzo que desde legislaturas pasadas se haya hecho en esta misma cámara para poder aprovechar con suficiencia esa realidad y adecuarla a la realidad presente.\n",
            "También es de humanos echar la culpa a los demás. Pero nosotros vamos a decir aquí lo que creemos que hay que hacer y espero que ustedes reflexionen.\n",
            "Y por lo tanto, vamos a apoyar evidentemente la enmienda de transacción que hemos acordado.\n",
            "Nada vuelvo a decirlo nada.\n",
            "No pretendo cambiar el orden constitucional y prácticamente mundial\n",
            "Y luego a nosotros la fundación nos parece perfecta.\n",
            "¿Sería un orgullo pertenecer a esta legislatura si lo consiguiéramos?\n",
            "Hablamos siempre de que queremos formar en competencias. Queremos enseñar a aprender.\n",
            "¿Por qué no ha querido entrar en una transaccional con ese tema?\n",
            "Sí, señor Arana. Efectivamente, en ese sentido va la iniciativa.\n",
            "No me diga que no con la cabeza.\n",
            "¿No permite que sea efectiva la justicia?\n",
            "Los costes energéticos de la red de transportes también tienen gran importancia económica y medioambiental.\n",
            "En eso debería centrarse este instituto, pero ustedes pretenden nuevamente mezclar unas cosas con otras.\n",
            "Esta iniciativa no es ninguna oportunidad.\n",
            "Yo no planteo un esquema bilateral para el final de eta, no?\n",
            "Yo creo que nos atañe a todos, y aquí está representada la voluntad popular.\n",
            "Baina hori da Benetan Arazoa Daukaguna?\n",
            "Porque estos trabajadores y trabajadoras lo que necesitaban, no era una declaración con la que puedo estar muy de acuerdo una declaración de buena voluntad.\n",
            "Desde el más absoluto respeto a todos los debates y a todas las iniciativas, voy a ser muy breve porque uno tiende a intentar no repetirse los argumentos y hay veces que es especialmente complicado cuando los debates se reiteran una y otra vez en esta cámara, y como pretendo ser coherente con no repetirme, voy a ser muy breve.\n",
            "Ciertamente fue una oportunidad perdida para acabar con esas políticas de imposición, pero sin embargo, y a los hechos me remito. Es que el partido socialista no quiso, y el partido popular no movió un dedo para acabar con estas políticas de imposición.\n",
            "decía el señor Agirrezabala que lo que importaba era el ámbito vasco de decisión.\n",
            "Saldrá aprobada y ojalá todos los parlamentarios de esta cámara. Voten a favor.\n",
            "El grupo socialista inicialmente nos proponía una cosa y finalmente nos propone otra cosa distinta.\n",
            "Yo creo que también eso es un error.\n",
            "Y por si todo esto no fuera suficiente, también se ha planteado la eliminación del puesto de inspección fronteriza para que así este aeropuerto sea menos competitivo.\n",
            "La Academia seguirá siendo un organismo público. Tendrá una regulación por ley como academia de policía y emergencias.\n",
            "¿Y a todos ustedes una feliz Navidad y que el año que viene sea mejor que este para todos?\n",
            "De esas no se acuerda?\n",
            "De ahí nuestras alegaciones y nuestras aportaciones.\n",
            "Pues bien, esta última reflexión tiene mucho que ver con estas palabras del señor Ares con las palabras, digo que nos gustaría que se viesen acompañadas también por los hechos.\n",
            "Porque todo lo demás, como todo el mundo sabe ha llevado permanentemente a un bloqueo.\n",
            "Y que en ese sentido también apoyó en esas dos horas de comparecencia en las que pudimos informarnos de cómo habían sido las atenciones.\n",
            "En definitiva, queremos vidas plenas frente a vidas amputadas por el capital.\n",
            "En una smart city o ciudad sostenible es imprescindible atacar los proyectos con una vision holística con una visión integral de la ciudad o del territorio al que nos dirigimos.\n",
            "Asimismo, existe un registro de la competencia que incluye el de los certificados de profesionalidad?\n",
            "No había más que presentarse, y el gobierno del Partido Popular no lo hizo.\n",
            "Pero además, se preveía la eliminación total del uso. Una vez se produjera la transición y se sustituyera por nuevos elementos de control de disturbios capaces de limitar al máximo el riesgo de cualquier lesión a las personas.\n",
            "Si antes de la discusión parlamentaria aquí los dos reales decretos no han sido declarados inconstitucionales, debemos aprovechar aquí la ocasión en el Parlamento Vasco para que la legislación autonómica reconduzca la situación y concilie esos intereses de las partes afectadas.\n",
            "El problema está como siempre en la demora en ejecutar por parte de este gobierno temas que parece que no considera prioritarios.\n",
            "Una vez más, no van a responder a las necesidades de la sociedad vasca ni en materia de protección ni en materia de empleo ni en materia de cohesión.\n",
            "Y todos nosotros estamos representando a la mayoría de la población vasca.\n",
            "Creemos conveniente o creíamos conveniente, aunque no aparece tan especificado en la enmienda, que en el órgano de coordinación tributaria se podía estudiar con las diputaciones forales la aplicación de nuevas medidas fiscales que beneficiasen tanto a propietarios como inquilinos y que, además de poner en el mercado viviendas en alquiler, también podría seguir para controlar precisamente y luchar contra un posible fraude ocultación de rendimientos sacados del alquiler de viviendas?\n",
            "En lo que se refiere al golpe de estado de franco, la guerra civil y la represión franquista. Obviamente, vemos positivo que se recuerde y que se haga un ejercicio de memoria histórica y que se recuerde a las personas que se recuerde a las víctimas que se recuerden los escenarios y los momentos históricos que fueron importantes en esa negra etapa de nuestra historia reciente.\n",
            "Pero ni gobierno ni instituto nacional de estadística ni bancos dan datos precisos.\n",
            "Eso es lo que va a hacer hoy el Partido Nacionalista, Vasco.\n",
            "Y entonces, ¿por qué quiere echarla para atrás?\n",
            "¿El partido popular de qué está a favor?\n",
            "Todos han tenido en su raíz la preservación o la recuperación de los derechos y soberanía del pueblo vasco para precisamente ser pueblo vasco.\n",
            "Así y todo pareciera que el camino se cierra una y otra vez.\n",
            "También la prioridad de la sostenibilidad del proyecto colectivo sobre los intereses de los grupos de interés es un elemento fundamental que hace que sean muy interesantes estas fórmulas económicas.\n",
            "Hasta un tercio de los atentados de eta están sin esclarecerse.\n",
            "Somos conscientes de quién tiene la competencia real en esta materia, pero creemos que hay muchas cosas que todavía pueden llevarse a cabo y siempre de la mano del Parlamento vasco y no aprobando decisiones al margen del mismo.\n",
            "Y lo único que hemos intentado en el último punto es precisamente eso que se valore su posible publificación.\n",
            "Y es que tal y como ha afirmado el Lehendakari Urkullu en diversas ocasiones, por ejemplo, en el último pleno de política general, la educación es un reto de país para el gobierno vasco?\n",
            "Desde un punto de vista técnico, hemos realizado también mejoras que aclaran y evitan posibles ambigüedades que generaban preocupación.\n",
            "Claro, y esto es otro elemento más de los muchos que aquí van saliendo a lo largo de los debates sobre cuál es el impulso que el gobierno aplica a estas cuestiones.\n",
            "El gobierno está mostrando flexibilidad a la hora de aplicarla. Hemos tendido la mano para poder abordar una nueva etapa a nuestro país, tratando de buscar un pacto por la educación.\n",
            "La señora Pinedo decía que quedó clara la posición de los distintos partidos políticos en aquel debate, y es cierto y se aprobó además una enmienda nuestra.\n"
          ]
        }
      ]
    }
  ]
}